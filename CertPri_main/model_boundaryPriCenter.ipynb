{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e7ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from art.utils import load_mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from art.metrics.metrics import empirical_robustness, clever_t, clever_u, clever, loss_sensitivity, wasserstein_distance\n",
    "# from art.metrics.metrics import inverper_c\n",
    "import numpy as np\n",
    "from art.estimators.classification.keras import KerasClassifier\n",
    "import logging\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3164cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_L1 = 40\n",
    "R_L2 = 2\n",
    "R_LI = 0.1\n",
    "\n",
    "def _create_krclassifier_FMNIST():\n",
    "    num_classes = 10\n",
    "    input_shape = (28,28,1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', name = 'block1_conv1', \n",
    "                     input_shape=input_shape))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn1'))\n",
    "    model.add(Activation('relu', name = 'block1_act1'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool1'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', name = 'block1_conv2'))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn2'))\n",
    "    model.add(Activation('relu', name = 'block1_act2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool2'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', name = 'block1_conv3'))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn3'))\n",
    "    model.add(Activation('relu', name = 'block1_act3'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool3'))\n",
    "    # top\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "    model.add(Dropout(0.5, name='drop1'))\n",
    "    model.add(Dense(32, activation='relu', name='fc2'))\n",
    "    model.add(Dropout(0.5, name='drop2'))\n",
    "    # model.add(Dense(64, activation='relu', name='fc3'))\n",
    "    # model.add(Dropout(0.5, name='drop3'))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "    \n",
    "    # model = load_model(\"./fmnist_CNN.h5\")\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Get the classifier\n",
    "    krc = KerasClassifier(model=model, clip_values=(0, 1), use_logits=False)\n",
    "\n",
    "    return krc\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a25b4349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1.4838 - accuracy: 0.5117 - val_loss: 0.4869 - val_accuracy: 0.8992\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.6083 - accuracy: 0.8126 - val_loss: 0.2427 - val_accuracy: 0.9360\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4261 - accuracy: 0.8716 - val_loss: 0.1696 - val_accuracy: 0.9512\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3410 - accuracy: 0.8992 - val_loss: 0.1399 - val_accuracy: 0.9592\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2902 - accuracy: 0.9143 - val_loss: 0.1216 - val_accuracy: 0.9666\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2475 - accuracy: 0.9274 - val_loss: 0.1037 - val_accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2214 - accuracy: 0.9349 - val_loss: 0.0979 - val_accuracy: 0.9734\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1994 - accuracy: 0.9428 - val_loss: 0.0824 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1852 - accuracy: 0.9464 - val_loss: 0.0809 - val_accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1724 - accuracy: 0.9492 - val_loss: 0.0747 - val_accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "# Get Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test), _, _ = load_mnist()\n",
    "\n",
    "# Get the classifier\n",
    "krc = _create_krclassifier_FMNIST()\n",
    "krc.fit(x_train, y_train, batch_size=256, nb_epochs=10, shuffle=True, # nb_epochs=5\n",
    "        validation_data=(x_test[0:5000], y_test[0:5000]), verbose=1)\n",
    "\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"./fmnist_CNN.h5\", \n",
    "#                                                     monitor='val_accuracy', \n",
    "#                                                     verbose=1, \n",
    "#                                                     save_best_only=True, mode = 'max')\n",
    "# callbacks_list = [checkpoint]\n",
    "# krc.fit(x_train, y_train, batch_size=256, epochs=20, shuffle=True,\n",
    "#           validation_data=(x_test[0:5000], y_test[0:5000]), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb48e9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini = []\n",
    "total_sample_num = 500\n",
    "predicted_confidence = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(total_sample_num)):\n",
    "    pre_tmp = krc.predict(np.reshape(x_test[index], [-1,28,28,1]))\n",
    "    Gini.append(1-np.sum(pre_tmp*pre_tmp))\n",
    "    predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ad32943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.9826666666666667\n",
      "RAUC:  0.9865996649916248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(Gini)\n",
    "indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b30fb05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "BoundaryGini = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(total_sample_num)):\n",
    "    pred = krc.predict(np.reshape(x_test[index], [-1,28,28,1]))\n",
    "    res_tmp = clever_u(krc, x_test[index], 3, 5, R_LI, norm=np.inf, pool_factor=3, verbose=False)\n",
    "    BoundaryGini.append(res_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "590ff5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.9846666666666667\n",
      "RAUC:  0.9886097152428811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(BoundaryGini)\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3970a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91e09336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "R_L1 = 40\n",
    "R_L2 = 2\n",
    "R_LI = 0.05\n",
    "BoundaryGini2 = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(total_sample_num)):\n",
    "    pred = krc.predict(np.reshape(x_test[index], [-1,28,28,1]))\n",
    "    res_tmp = inverper_c(krc, x_test[index], 3, 5, R_LI, norm=np.inf, pool_factor=3)\n",
    "    BoundaryGini2.append(res_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a14f39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.9846666666666667\n",
      "RAUC:  0.9886097152428811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(BoundaryGini2)\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16dee718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 1, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort([1,5,3,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a069a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4812f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from functools import reduce\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Union, TYPE_CHECKING\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy.optimize import fmin as scipy_optimizer\n",
    "from scipy.stats import weibull_min\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
    "from art.utils import random_sphere\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from art.attacks.attack import EvasionAttack\n",
    "    from art.utils import CLASSIFIER_TYPE, CLASSIFIER_LOSS_GRADIENTS_TYPE, CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE\n",
    "    \n",
    "def inverper_c(\n",
    "    classifier: \"CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE\",\n",
    "    x: np.ndarray,\n",
    "    nb_batches: int,\n",
    "    batch_size: int,\n",
    "    radius: float,\n",
    "    norm: float,\n",
    "    c_init: float = 1.0,\n",
    "    pool_factor: int = 10,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute CLEVER score for a targeted attack.\n",
    "\n",
    "    | Paper link: https://arxiv.org/abs/1801.10578\n",
    "\n",
    "    :param classifier: A trained model.\n",
    "    :param x: One input sample.\n",
    "    :param nb_batches: Number of repetitions of the estimate.\n",
    "    :param batch_size: Number of random examples to sample per batch.\n",
    "    :param radius: Radius of the maximum perturbation.\n",
    "    :param norm: Current support: 1, 2, np.inf.\n",
    "    :param c_init: Initialization of Weibull distribution.\n",
    "    :param pool_factor: The factor to create a pool of random samples with size pool_factor x n_s.\n",
    "    :return: CLEVER score.\n",
    "    \"\"\"\n",
    "    # Check if the targeted class is different from the predicted class\n",
    "    y_pred = classifier.predict(np.array([x]))\n",
    "    pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "\n",
    "    # Check if pool_factor is smaller than 1\n",
    "    if pool_factor < 1:  # pragma: no cover\n",
    "        raise ValueError(\"The `pool_factor` must be larger than 1.\")\n",
    "\n",
    "    # Some auxiliary vars\n",
    "    rand_pool_grad_set = []\n",
    "    grad_norm_set = []\n",
    "    dim = reduce(lambda x_, y: x_ * y, x.shape, 1)\n",
    "    shape = [pool_factor * batch_size]\n",
    "    shape.extend(x.shape)\n",
    "\n",
    "    # Generate a pool of samples\n",
    "    rand_pool = np.reshape(\n",
    "        random_sphere(nb_points=pool_factor * batch_size, nb_dims=dim, radius=radius, norm=norm),\n",
    "        shape,\n",
    "    )\n",
    "    rand_pool += np.repeat(np.array([x]), pool_factor * batch_size, 0)\n",
    "    rand_pool = rand_pool.astype(ART_NUMPY_DTYPE)\n",
    "    if hasattr(classifier, \"clip_values\") and classifier.clip_values is not None:\n",
    "        np.clip(rand_pool, classifier.clip_values[0], classifier.clip_values[1], out=rand_pool)\n",
    "\n",
    "    # Change norm since q = p / (p-1)\n",
    "    if norm == 1:\n",
    "        norm = np.inf\n",
    "    elif norm == np.inf:\n",
    "        norm = 1\n",
    "    elif norm != 2:  # pragma: no cover\n",
    "        raise ValueError(f\"Norm {norm} not supported\")\n",
    "\n",
    "    # Compute gradients for all samples in rand_pool\n",
    "    for i in range(batch_size):\n",
    "        rand_pool_batch = rand_pool[i * pool_factor : (i + 1) * pool_factor]\n",
    "\n",
    "        # Compute gradients\n",
    "        grad_pred_class = classifier.class_gradient(rand_pool_batch, label=pred_class)\n",
    "\n",
    "        if np.isnan(grad_pred_class).any() :  # pragma: no cover\n",
    "            raise Exception(\"The classifier results NaN gradients.\")\n",
    "\n",
    "        grad = grad_pred_class\n",
    "        grad = np.reshape(grad, (pool_factor, -1))\n",
    "        grad = np.linalg.norm(grad, ord=norm, axis=1)\n",
    "        rand_pool_grad_set.extend(grad)\n",
    "\n",
    "    rand_pool_grads = np.array(rand_pool_grad_set)\n",
    "\n",
    "    # Loop over the batches\n",
    "    for _ in range(nb_batches):\n",
    "        # Random selection of gradients\n",
    "        grad_norm = rand_pool_grads[np.random.choice(pool_factor * batch_size, batch_size)]\n",
    "        grad_norm = np.max(grad_norm)\n",
    "        grad_norm_set.append(grad_norm)\n",
    "\n",
    "    # Maximum likelihood estimation for max gradient norms\n",
    "    [_, loc, _] = weibull_min.fit(-np.array(grad_norm_set), c_init, optimizer=scipy_optimizer)\n",
    "\n",
    "    # Compute function value\n",
    "    values = classifier.predict(np.array([x]))\n",
    "    value = values[:, pred_class] - 0.5\n",
    "\n",
    "    # Compute scores\n",
    "#     score = np.min([-value[0] / loc, radius])\n",
    "    score = -value[0] / loc\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ace6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
