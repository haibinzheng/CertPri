{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b61167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as BE\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from progressbar import ProgressBar\n",
    "import os\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "\n",
    "# from tensorflow.keras import backend as BE\n",
    "# from Integrated_Gradients_algorithm import *\n",
    "# from GradVisualizer import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess=tf.compat.v1.Session(config=config) \n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d6a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0ab301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('./featureExtraction/ImageNet_1616samples_AdvOrg.npy', allow_pickle=True)\n",
    "data = np.load('./featureExtraction/ImageNet_556samples_OneStepAdvOrg.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee0ed5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_adv', 'X_org', 'ground_truth_label', 'X_adv_predicted_confidence', 'predicted_confidence', 'index1'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.item().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60cf557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "top_set = 1 # 预测的前n个类中包含真实标签则表示预测正确\n",
    "total_sample_num = len(data.item()['index1'])\n",
    "img_num = range(0, total_sample_num)\n",
    "ground_truth_label = []  # 记录样本的真实标签\n",
    "predicted_confidence = []  # 记录样本的置信度信息\n",
    "binary_flag = [] # 记录是否为对抗样本，是为1，否为0，误分类的为-1\n",
    "gradients = []\n",
    "second_gradients = []\n",
    "num_class = 1000\n",
    "\n",
    "# 先计算对抗样本的梯度\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(img_num):\n",
    "    x_tmp = data.item()['X_adv'][i]\n",
    "#     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "    pre_tmp = data.item()['X_adv_predicted_confidence'][i]\n",
    "    predicted_confidence.append(pre_tmp)\n",
    "    label_tmp = data.item()['ground_truth_label'][i]\n",
    "    ground_truth_label.append(label_tmp)\n",
    "    binary_flag.append(1)\n",
    "    \n",
    "#     target_one_hot = np.reshape(to_categorical(np.argmax(pre_tmp), num_class),(1,-1))\n",
    "#     grads = get_loss_gradients(x_tmp, base_model, target_one_hot)\n",
    "    grads = PreGradientEstimator(samples = 6, sigma=1, model = base_model, x=x_tmp, \n",
    "                                 bounds=(np.min(x_tmp),np.max(x_tmp)), noise_mu=0, nise_std=1, \n",
    "                                 top_pred_idx = np.argmax(pre_tmp), clip=True)\n",
    "    gradients.append(grads)\n",
    "    \n",
    "#     grads = get_gradients(x_tmp, base_model, np.argmax(pre_tmp))\n",
    "#     gradients.append(grads)\n",
    "#     target_label = np.argsort(-pre_tmp) \n",
    "#     target_label = target_label[:,1][0]\n",
    "#     grads = get_gradients(x_tmp, base_model, target_label)\n",
    "#     second_gradients.append(grads)\n",
    "    \n",
    "# 再计算正常样本的梯度\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(img_num):\n",
    "    x_tmp = data.item()['X_org'][i]\n",
    "#     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "    pre_tmp = data.item()['predicted_confidence'][i]\n",
    "    predicted_confidence.append(pre_tmp)\n",
    "    label_tmp = data.item()['ground_truth_label'][i]\n",
    "    ground_truth_label.append(label_tmp)\n",
    "    binary_flag.append(0)\n",
    "    \n",
    "#     target_one_hot = np.reshape(to_categorical(np.argmax(pre_tmp), num_class),(1,-1))\n",
    "#     grads = get_loss_gradients(x_tmp, base_model, target_one_hot)\n",
    "    grads = PreGradientEstimator(samples = 6, sigma=1, model = base_model, x=x_tmp, \n",
    "                                 bounds=(np.min(x_tmp),np.max(x_tmp)), noise_mu=0, nise_std=1,\n",
    "                                 top_pred_idx = np.argmax(pre_tmp), clip=True)\n",
    "    gradients.append(grads)\n",
    "    \n",
    "#     grads = get_gradients(x_tmp, base_model, np.argmax(pre_tmp))\n",
    "#     gradients.append(grads)\n",
    "#     target_label = np.argsort(-pre_tmp) \n",
    "#     target_label = target_label[:,1][0]\n",
    "#     grads = get_gradients(x_tmp, base_model, target_label)\n",
    "#     second_gradients.append(grads)\n",
    "\n",
    "# # 最后计算原始数据集中被误分类的样本的梯度\n",
    "# DATA_PATH = '../datasets/ImageNetVal/'\n",
    "# file_name = getfile_name(DATA_PATH)\n",
    "# file_name = np.sort(file_name) \n",
    "# synsets = scipy.io.loadmat(os.path.join('../datasets', 'ILSVRC2012_devkit_t12', 'data', 'meta.mat'))['synsets']\n",
    "# WNID = [s[0][1][0] for s in synsets]\n",
    "# f = open(\"../datasets/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt\",encoding = \"utf-8\")\n",
    "# val_ground_truth = f.read()\n",
    "# val_ground_truth = val_ground_truth.split('\\n')\n",
    "# for i in range(len(val_ground_truth)-1):\n",
    "#     val_ground_truth[i] = int(val_ground_truth[i])\n",
    "\n",
    "# pbar = ProgressBar()\n",
    "# for i in pbar(range(0,3000)):\n",
    "#     img_path = DATA_PATH + file_name[i]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "#     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "    \n",
    "#     if not get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), \n",
    "#                ground_truth=WNID[val_ground_truth[i]-1]): # 选取被错误分类的样本\n",
    "#         pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "#         predicted_confidence.append(pre_tmp)\n",
    "#         ground_truth_label.append(WNID[val_ground_truth[i]-1])\n",
    "\n",
    "#         target_one_hot = np.reshape(to_categorical(np.argmax(pre_tmp), num_class),(1,-1))\n",
    "#         grads = get_loss_gradients(x_tmp, base_model, target_one_hot)\n",
    "#         gradients.append(grads)\n",
    "#         binary_flag.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "036e94e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(binary_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc58ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a87a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./featureExtraction/ImageNet_'+str(total_sample_num)+'samples_AdvOrgMis_GradientFeature.npy',{\n",
    "#     'ground_truth_label': np.array(ground_truth_label),\n",
    "#     'predicted_confidence': np.array(predicted_confidence),\n",
    "#     'binary_flag': np.array(binary_flag),\n",
    "#     'gradients': np.array(gradients),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d07d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11656f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini = []\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(0, len(binary_flag))):\n",
    "    Gini.append(np.sum(np.abs(gradients[i])))\n",
    "    \n",
    "#     tmp1 = (np.abs(second_gradients[i]) - np.abs(gradients[i]))/np.abs(gradients[i])\n",
    "#     Gini.append(np.sum(np.abs(tmp1)))\n",
    "    \n",
    "#     Gini.append(1-np.sum(predicted_confidence[i]*predicted_confidence[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6789e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.639857538429688\n",
      "RAUC:  0.8520330530063667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(Gini)\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,wrong_num_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                    predicted_confidence=np.array(predicted_confidence), top_set=top_set,\n",
    "                   decode_predictions=decode_predictions)\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                    predicted_confidence=np.array(predicted_confidence), top_set=top_set,\n",
    "                    decode_predictions=decode_predictions)\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d0e6a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91107e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb4ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
