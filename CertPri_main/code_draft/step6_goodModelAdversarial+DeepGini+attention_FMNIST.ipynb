{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b61167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from progressbar import ProgressBar\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as BE\n",
    "from Integrated_Gradients_algorithm import *\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess=tf.compat.v1.Session(config=config)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "def get_loss_gradients(img_input, model, target_one_hot, from_logits=False):\n",
    "    images = tf.cast(img_input, tf.float32)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=from_logits)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        preds = model(images)\n",
    "        loss = cce(target_one_hot, preds)\n",
    "#         top_class = preds[:, top_pred_idx]\n",
    "\n",
    "    grads = tape.gradient(loss, images)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08df765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(predict_label, ground_truth=None):\n",
    "    for i in predict_label[0]:\n",
    "        if i[0] == ground_truth:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def softmax( f ):\n",
    "    # instead: first shift the values of f so that the highest number is 0:\n",
    "    f -= np.max(f) # f becomes [-666, -333, 0]\n",
    "    return np.exp(f) / np.sum(np.exp(f))  # safe to do, gives the correct answer\n",
    "\n",
    "def get_APFD(Gini_indexs, ground_truth_label, predicted_confidence, top_set=None):\n",
    "    o_i = 0\n",
    "    pbar = ProgressBar()\n",
    "    wrong_num = 0\n",
    "    for i in pbar(range(0, len(Gini_indexs))):\n",
    "        if top_set is not None:\n",
    "            if not get_acc(predict_label=decode_predictions(predicted_confidence[Gini_indexs[i]], top=top_set), \n",
    "                           ground_truth=ground_truth_label[Gini_indexs[i]]):\n",
    "                o_i = o_i+i\n",
    "#                 print(i, o_i)\n",
    "                wrong_num = wrong_num+1\n",
    "        else:\n",
    "            if np.argmax(ground_truth_label[Gini_indexs[i]]) != np.argmax(predicted_confidence[Gini_indexs[i]]):\n",
    "                o_i = o_i+i\n",
    "                wrong_num = wrong_num+1\n",
    "    APFD = 1 - o_i/(len(Gini_indexs)*wrong_num) + 1/(2*len(Gini_indexs))\n",
    "    return APFD, len(Gini_indexs), wrong_num\n",
    "\n",
    "def get_RAUC(Gini_indexs, ground_truth_label, predicted_confidence, top_set=None):\n",
    "    pre_y_axis = []\n",
    "    o_i = 0\n",
    "    wrong_num = 0\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(range(0, len(Gini_indexs))):\n",
    "        if top_set is not None:\n",
    "            if not get_acc(predict_label=decode_predictions(predicted_confidence[Gini_indexs[i]], top=top_set), \n",
    "                           ground_truth=ground_truth_label[Gini_indexs[i]]):  \n",
    "                o_i = o_i+1\n",
    "                wrong_num = wrong_num+1\n",
    "                pre_y_axis.append(o_i)\n",
    "            else:\n",
    "                pre_y_axis.append(o_i)\n",
    "        else:\n",
    "            if np.argmax(ground_truth_label[Gini_indexs[i]]) != np.argmax(predicted_confidence[Gini_indexs[i]]):\n",
    "                o_i = o_i+1\n",
    "                wrong_num = wrong_num+1\n",
    "                pre_y_axis.append(o_i)\n",
    "            else:\n",
    "                pre_y_axis.append(o_i)\n",
    "    true_y_axis = wrong_num*(len(Gini_indexs)-wrong_num) + (wrong_num+1)*wrong_num/2\n",
    "    RAUC = np.sum(pre_y_axis)/true_y_axis\n",
    "#     print(\"RAUC: \", RAUC)\n",
    "    return RAUC, len(Gini_indexs), wrong_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992b6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "X_train = np.reshape(X_train,[-1,28*28])/255.0\n",
    "X_test = np.reshape(X_test,[-1,28*28])/255.0\n",
    "Y_train = to_categorical(Y_train,10)\n",
    "Y_test = to_categorical(Y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc88dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 28*28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape=(input_shape,), units=input_shape, activation='relu'))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # model training\n",
    "# model.fit(X_train, Y_train, epochs=10, batch_size=512)\n",
    "\n",
    "# MODEL_PATH = \"/public/liujiawei/huawei/ZHB/ADF-master/models/\"\n",
    "# model.save(MODEL_PATH+\"fmnist_FC5_good.h5\")\n",
    "\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85833ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/public/liujiawei/huawei/ZHB/ADF-master/models/\"\n",
    "model = load_model(MODEL_PATH+\"fmnist_FC5_good.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65d88ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 4s 17ms/step - loss: 0.3493 - accuracy: 0.8772\n",
      "accuracy 0.8772000074386597\n"
     ]
    }
   ],
   "source": [
    "loss_acc = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('accuracy', loss_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ab7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adversarial attack\n",
    "# from tensorflow.keras import backend as BE\n",
    "\n",
    "# max_iter = 5e+2\n",
    "# examples_num1 = 1000\n",
    "# decay_factor_gradent = 0.9\n",
    "# max_iter = 100\n",
    "# epsilon_lr = 1.0/max_iter*2\n",
    "# # decay_factor_epsilon_lr = 0.99\n",
    "\n",
    "# # x_GE = np.zeros((1, 28*28))\n",
    "# # per_tmp = model.predict(x_GE)\n",
    "# # label_tmp = np.argmax(per_tmp)\n",
    "\n",
    "# # grads = BE.gradients(loss = BE.categorical_crossentropy([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1], model.layers[-1].output[:,:]), variables = model.inputs)\n",
    "# # grads = BE.gradients(loss = model.layers[-1].output[:,label_tmp], variables = model.inputs)\n",
    "# # get_gradients = BE.function(inputs=model.inputs[0], outputs=grads)\n",
    "\n",
    "# x_adv = []\n",
    "# X_test_part = X_test[0:examples_num1]\n",
    "# Y_test_part = Y_test[0:examples_num1]\n",
    "\n",
    "# for i1, x_tmp in enumerate(X_test_part):\n",
    "#     x_tmp = x_tmp.reshape(-1,28*28)\n",
    "#     y_tmp = Y_test_part[i1]\n",
    "#     x_append = x_tmp\n",
    "#     if np.argmax(model.predict(x_tmp)) == np.argmax(y_tmp) :\n",
    "# #         print(1)\n",
    "#         # 获取目标攻击的标签\n",
    "#         y_pre_tmp = model.predict(x_tmp)\n",
    "#         target_label = np.argsort(-y_pre_tmp) \n",
    "#         target_label = target_label[:,1][0]  # 置信度第二高的标签，作为目标标签\n",
    "        \n",
    "#         # 计算目标攻击的对抗样本\n",
    "#         grads = BE.gradients(loss = model.layers[-1].output[:,target_label], variables = model.inputs)\n",
    "#         get_gradients = BE.function(inputs=model.inputs[0], outputs=grads)\n",
    "#         x_moment = 0\n",
    "#         print(\"process:{}%\".format(i1/examples_num1*100))\n",
    "#         for iter1 in range(0, max_iter):\n",
    "#             x_grad = get_gradients(x_tmp)[0]  #获取梯度\n",
    "#             x_moment = x_moment * decay_factor_gradent + x_grad  #计算动量\n",
    "#     #         epsilon_lr = epsilon_lr * decay_factor_epsilon_lr # 扰动衰减\n",
    "#             x_tmp = x_tmp + x_moment * epsilon_lr # 添加扰动\n",
    "#             x_tmp = np.clip(x_tmp, 0, 1)\n",
    "\n",
    "#     #         print(np.argmax(model.predict(x_tmp)), np.argmax(y_tmp))\n",
    "#             if np.argmax(model.predict(x_tmp)) != np.argmax(y_tmp) : # 判断是否成为对抗样本\n",
    "#                 x_append = x_tmp\n",
    "#                 print(\"succeed!\")\n",
    "#                 break\n",
    "                \n",
    "#     x_adv.append(x_append)\n",
    "\n",
    "# X_adv = np.reshape(x_adv, [-1,28*28])\n",
    "# Y_adv = Y_test_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3963d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ca783b2b2275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 导入对抗样本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'fmnist_Xadv1000.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mY_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'fmnist_Yadv_true1000.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/public/liujiawei/huawei/ZHB/ADF-master/mnist/'\n",
    "\n",
    "# # 保存对抗样本\n",
    "# np.save(DATA_PATH + 'fmnist_Xadv1000.npy', X_adv)\n",
    "# np.save(DATA_PATH + 'fmnist_Yadv_true1000.npy', Y_adv)\n",
    "\n",
    "# 导入对抗样本\n",
    "X_adv = np.load(DATA_PATH + 'fmnist_Xadv1000.npy')\n",
    "Y_adv = np.load(DATA_PATH + 'fmnist_Yadv_true1000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428a5fd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6dddf4545926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 可视化正常样本和对抗样本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 可视化正常样本和对抗样本\n",
    "\n",
    "plt.figure()\n",
    "hang = 4\n",
    "lie = 5\n",
    "for i in range(0,hang):\n",
    "    for j in range(0,lie):\n",
    "        plt.subplot(hang,lie,i*lie+j+1)\n",
    "        plt.imshow(X_test[i*lie+j].reshape((28,28,1)))\n",
    "#         print(np.argmax(model.predict(X_test_part[i*lie+j].reshape(-1, 28*28))))\n",
    "        \n",
    "plt.figure()\n",
    "hang = 4\n",
    "lie = 5\n",
    "for i in range(0,hang):\n",
    "    for j in range(0,lie):\n",
    "        plt.subplot(hang,lie,i*lie+j+1)\n",
    "        plt.imshow(X_adv[i*lie+j].reshape((28,28,1)))\n",
    "#         print(np.argmax(model.predict(X_adv[i*lie+j].reshape(-1, 28*28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e0e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.4090\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 检查数据是否有问题\n",
    "loss_acc = model.evaluate(X_adv, Y_adv)\n",
    "print(np.shape(X_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe51437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD: 0.7053274111675126\n",
      "RAUC: 0.9997551931454081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Gini = []\n",
    "predicted_confidence = []\n",
    "pbar = ProgressBar()\n",
    "for x_tmp in pbar(X_adv):\n",
    "    per_tmp = model.predict(x_tmp.reshape([-1,28*28]))\n",
    "    label_tmp = np.argmax(per_tmp)\n",
    "    Gini_tmp = 1-np.sum(per_tmp*per_tmp)\n",
    "#     Gini_tmp = -np.sum(per_tmp*np.log2(per_tmp))\n",
    "    Gini.append(Gini_tmp)\n",
    "    predicted_confidence.append(per_tmp)\n",
    "    \n",
    "indexs = np.argsort(Gini)\n",
    "indexs = indexs[::-1]\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('APFD:', APFD)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('RAUC:', RAUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9cf4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini = []\n",
    "# index1 = 0\n",
    "# index2 = 0\n",
    "# pbar = ProgressBar()\n",
    "# for x_tmp in pbar(X_adv):\n",
    "#     per_tmp = model.predict(x_tmp.reshape([-1,28*28]))\n",
    "#     label_tmp = np.argmax(per_tmp)\n",
    "#     if label_tmp == np.argmax(Y_adv[index1]):\n",
    "#         index2 = index2 +1\n",
    "#     index1 = index1 + 1\n",
    "#     Gini_tmp = 1-np.sum(per_tmp*per_tmp)\n",
    "# #     Gini_tmp = -np.sum(per_tmp*np.log2(per_tmp))\n",
    "#     Gini.append(Gini_tmp)\n",
    "    \n",
    "# indexs = np.argsort(Gini)\n",
    "# indexs = indexs[::-1]\n",
    "\n",
    "# pbar = ProgressBar()\n",
    "# o_i = 0\n",
    "# for i in pbar(range(0, (index1))):\n",
    "#     x_tmp = X_adv[indexs[i]].reshape([-1,28*28])\n",
    "#     y_tmp = Y_adv[indexs[i]]\n",
    "#     per_tmp = model.predict(x_tmp)\n",
    "#     if np.argmax(y_tmp)!=np.argmax(per_tmp):\n",
    "#         o_i = o_i+i\n",
    "# APFD = 1-o_i/(index1*(index1-index2))+1/(2*index1)\n",
    "# print(APFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2034b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# use one layer's activation\n",
    "pbar = ProgressBar()\n",
    "# layer_pos = -2\n",
    "# get_activations = BE.function(inputs=model.inputs[0], outputs=model.layers[layer_pos].output[:,:])\n",
    "grads_pre1 = []\n",
    "grads_pre2 = []\n",
    "grads_CE = []\n",
    "grads_CE2 = []\n",
    "num_class = 10\n",
    "# predicted_confidence = []\n",
    "# ground_truth_label = []\n",
    "for x_tmp in pbar(X_adv):\n",
    "    x_tmp = x_tmp.reshape([-1,28*28])\n",
    "    preds = model.predict(x_tmp)\n",
    "    \n",
    "    #     使用预测标签当做真实标签验证\n",
    "    label1 = np.argmax(preds[0])\n",
    "    grads = get_gradients(img_input=x_tmp, model=model, top_pred_idx=label1)\n",
    "    grads = np.sum(np.abs(grads))\n",
    "    grads_pre1.append(grads)\n",
    "    \n",
    "    target_one_hot = np.reshape(to_categorical(label1, num_class), (-1, num_class))\n",
    "    grads = get_loss_gradients(img_input=x_tmp, model=model, target_one_hot=target_one_hot)\n",
    "    grads = np.sum(np.abs(grads))\n",
    "    grads_CE.append(grads)\n",
    "    \n",
    "    preds[0][label1] = 0\n",
    "    label2 = np.argmax(preds[0])\n",
    "    grads = get_gradients(img_input=x_tmp, model=model, top_pred_idx=label2)\n",
    "    grads = np.sum(np.abs(grads))\n",
    "    grads_pre2.append(grads)\n",
    "    \n",
    "    target_one_hot = np.reshape(to_categorical(label2, num_class), (-1, num_class))\n",
    "    grads = get_loss_gradients(img_input=x_tmp, model=model, target_one_hot=target_one_hot)\n",
    "    grads = np.sum(np.abs(grads))\n",
    "    grads_CE2.append(grads)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # 使用attention机制\n",
    "#     x_act = softmax(get_activations(x_tmp.reshape([-1,28*28])))\n",
    "#     att1 = np.dot(np.transpose(x_act), x_act)\n",
    "#     att_weight = np.sum(att1, axis = 1).reshape(np.shape(x_act))\n",
    "#     x_act_ = softmax(x_act*att_weight)\n",
    "#     Gini_tmp = 1-np.sum(x_act_*x_act_)\n",
    "#     Gini_act.append(Gini_tmp)\n",
    "    \n",
    "#     predicted_confidence.append(model.predict(x_tmp.reshape([-1,28*28])))\n",
    "#      # 未使用attention机制\n",
    "#     x_act = softmax(get_activations(x_tmp.reshape([-1,28*28])))\n",
    "#     Gini_tmp = 1-np.sum(x_act*x_act)\n",
    "#     Gini_act.append(Gini_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7ce4704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD: 0.4521311336717428\n",
      "RAUC: 0.6406115371230394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Gini_act =[]\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(len(grads_CE))):\n",
    "#     x_act = np.sum(np.abs(grads_CE[i]))\n",
    "    x_act =[np.sum(np.abs(grads_CE[i])),\n",
    "            np.sum(np.abs(grads_CE2[i])),\n",
    "#             np.sum(np.abs(grads_CE_min[i])),\n",
    "#             np.sum(np.abs(grads_RCE[i])),\n",
    "#             np.sum(np.abs(grads_CE_ave[i])),\n",
    "            np.sum(np.abs(grads_pre1[i])),\n",
    "            np.sum(np.abs(grads_pre2[i])),\n",
    "#             np.sum(np.abs(grads_pre_min[i]))\n",
    "           ]\n",
    "#     print(i,':',x_act)\n",
    "    Gini_act.append(x_act)\n",
    "    \n",
    "Gini_act = np.array(Gini_act)\n",
    "indexs = np.argsort(1-Gini_act[:,0]/Gini_act[:,1])\n",
    "# indexs = indexs[::-1]\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('APFD:', APFD)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('RAUC:', RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42fbbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD: 0.5934103214890016\n",
      "RAUC: 0.8410075482113499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('APFD:', APFD)\n",
    "\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv, \n",
    "                predicted_confidence=np.array(predicted_confidence))\n",
    "print('RAUC:', RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d156d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5934103214890016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # use all layers' activation\n",
    "# pbar = ProgressBar()\n",
    "# get_activations1 = BE.function(inputs=model.inputs[0], outputs=model.layers[-2].output[:,:])\n",
    "# get_activations2 = BE.function(inputs=model.inputs[0], outputs=model.layers[-3].output[:,:])\n",
    "# get_activations3 = BE.function(inputs=model.inputs[0], outputs=model.layers[-4].output[:,:])\n",
    "# Gini_act = []\n",
    "# for x_tmp in pbar(X_adv):\n",
    "#     x_act1 = softmax(get_activations1(x_tmp.reshape([-1,28*28])))\n",
    "#     x_act2 = softmax(get_activations2(x_tmp.reshape([-1,28*28])))\n",
    "#     x_act3 = softmax(get_activations3(x_tmp.reshape([-1,28*28])))\n",
    "# #     Gini_tmp = 1-(np.sum(x_act1*x_act1)+np.sum(x_act2*x_act2)+np.sum(x_act3*x_act3))/3   # 基尼系数\n",
    "# #     Gini_tmp = 1-np.sum(x_act3*x_act3)\n",
    "#     Gini_tmp = (-np.sum(x_act1*np.log2(x_act1))-np.sum(x_act2*np.log2(x_act2))-np.sum(x_act3*np.log2(x_act3)))/3  # 信息熵\n",
    "#     Gini_act.append(Gini_tmp)\n",
    "\n",
    "# # use one layer's activation\n",
    "# pbar = ProgressBar()\n",
    "# layer_pos = -2\n",
    "# get_activations = BE.function(inputs=model.inputs[0], outputs=model.layers[layer_pos].output[:,:])\n",
    "# Gini_act = []\n",
    "# for x_tmp in pbar(X_adv):\n",
    "    \n",
    "#     # 使用attention机制\n",
    "#     x_act = softmax(get_activations(x_tmp.reshape([-1,28*28])))\n",
    "#     att1 = np.dot(np.transpose(x_act), x_act)\n",
    "#     att_weight = np.sum(att1, axis = 1).reshape(np.shape(x_act))\n",
    "#     x_act_ = softmax(x_act*att_weight)\n",
    "#     Gini_tmp = 1-np.sum(x_act_*x_act_)\n",
    "#     Gini_act.append(Gini_tmp)\n",
    "    \n",
    "# #      # 未使用attention机制\n",
    "# #     x_act = softmax(get_activations(x_tmp.reshape([-1,28*28])))\n",
    "# #     Gini_tmp = 1-np.sum(x_act*x_act)\n",
    "# #     Gini_act.append(Gini_tmp)\n",
    "\n",
    "# indexs = np.argsort(Gini_act)\n",
    "# indexs = indexs[::-1]\n",
    "# o_i = 0\n",
    "# pbar = ProgressBar()\n",
    "# for i in pbar(range(0, (index1))):\n",
    "#     x_tmp = X_adv[indexs[i]].reshape([-1,28*28])\n",
    "#     y_tmp = Y_adv[indexs[i]]\n",
    "#     per_tmp = model.predict(x_tmp)\n",
    "#     if np.argmax(y_tmp)!=np.argmax(per_tmp):\n",
    "#         o_i = o_i+i\n",
    "# APFD = 1-o_i/(index1*(index1-index2))+1/(2*index1)\n",
    "# print(APFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cedbb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "APFD 基于基尼系数\n",
    "# 0.7991785109983078 #使用所有层\n",
    "# 0.7736928934010152 #倒数第四层\n",
    "# 0.7608011844331641 #倒数第三层\n",
    "# 0.7998722504230118 #倒数第二层\n",
    "\n",
    "APFD 基于信息熵\n",
    "# 0.7873274111675126 #使用所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf717301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n",
      "(64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_act))\n",
    "# print(x_act)\n",
    "print(np.shape(np.transpose(x_act)))\n",
    "# print(np.transpose(x_act))\n",
    "\n",
    "att1 = np.dot(np.transpose(x_act), x_act)\n",
    "\n",
    "print(np.shape(att1))\n",
    "# print(att1)\n",
    "\n",
    "att_weight = np.sum(att1, axis = 1).reshape(np.shape(x_act))\n",
    "print(np.shape(att_weight))\n",
    "print(np.shape(x_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b185135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(1, 64)\n",
      "(1, 64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602983a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
