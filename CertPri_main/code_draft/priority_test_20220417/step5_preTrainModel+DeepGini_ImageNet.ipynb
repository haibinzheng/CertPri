{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b61167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from progressbar import ProgressBar\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# from tensorflow.keras import backend as BE\n",
    "# from Integrated_Gradients_algorithm import *\n",
    "# from GradVisualizer import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess=tf.compat.v1.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7b5a05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(predict_label, ground_truth=None):\n",
    "    for i in predict_label[0]:\n",
    "        if i[0] == ground_truth:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def softmax( f ):\n",
    "    # instead: first shift the values of f so that the highest number is 0:\n",
    "    f -= np.max(f) # f becomes [-666, -333, 0]\n",
    "    return np.exp(f) / np.sum(np.exp(f))  # safe to do, gives the correct answer\n",
    "\n",
    "\n",
    "# def get_APFD_ImageNet(Gini, WNID, predicted_confidence, top_set=None):\n",
    "#     Gini = np.array(Gini)\n",
    "#     indexs = np.argsort(Gini)[::-1]\n",
    "\n",
    "#     o_i = 0\n",
    "#     pbar = ProgressBar()\n",
    "#     wrong_num = 0\n",
    "#     for i in pbar(range(0, len(Gini))):\n",
    "#         if top_set is not None:\n",
    "#             if not get_acc(predict_label=decode_predictions(predicted_confidence[indexs[i]], top=top_set), ground_truth=WNID[val_ground_truth[indexs[i]]-1]):\n",
    "#                 o_i = o_i+i\n",
    "#                 print(i, o_i)\n",
    "#                 wrong_num = wrong_num+1\n",
    "\n",
    "#     APFD = 1 - o_i/(len(Gini)*wrong_num) + 1/(2*len(Gini))\n",
    "#     print(o_i, len(Gini),wrong_num)\n",
    "#     return APFD\n",
    "\n",
    "\n",
    "def get_APFD(Gini_indexs, ground_truth_label, predicted_confidence, top_set=None):\n",
    "    o_i = 0\n",
    "    pbar = ProgressBar()\n",
    "    wrong_num = 0\n",
    "    wrong_num_index = []\n",
    "    for i in pbar(range(0, len(Gini_indexs))):\n",
    "        if top_set is not None:\n",
    "            if not get_acc(predict_label=decode_predictions(predicted_confidence[Gini_indexs[i]], top=top_set), \n",
    "                           ground_truth=ground_truth_label[Gini_indexs[i]]):\n",
    "                o_i = o_i+i\n",
    "#                 print(i, o_i)\n",
    "                wrong_num = wrong_num+1\n",
    "                wrong_num_index.append(Gini_indexs[i])\n",
    "        else:\n",
    "            if np.argmax(ground_truth_label[Gini_indexs[i]]) != np.argmax(predicted_confidence[Gini_indexs[i]]):\n",
    "                o_i = o_i+i\n",
    "                wrong_num = wrong_num+1\n",
    "                wrong_num_index.append(Gini_indexs[i])\n",
    "    APFD = 1 - o_i/(len(Gini_indexs)*wrong_num) + 1/(2*len(Gini_indexs))\n",
    "    return APFD, wrong_num, np.array(wrong_num_index).reshape(-1)\n",
    "\n",
    "\n",
    "def get_RAUC(Gini_indexs, ground_truth_label, predicted_confidence, top_set=None):\n",
    "    pre_y_axis = []\n",
    "    o_i = 0\n",
    "    wrong_num = 0\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(range(0, len(Gini_indexs))):\n",
    "        if top_set is not None:\n",
    "            if not get_acc(predict_label=decode_predictions(predicted_confidence[Gini_indexs[i]], top=top_set), \n",
    "                           ground_truth=ground_truth_label[Gini_indexs[i]]):  \n",
    "                o_i = o_i+1\n",
    "                wrong_num = wrong_num+1\n",
    "                pre_y_axis.append(o_i)\n",
    "            else:\n",
    "                pre_y_axis.append(o_i)\n",
    "        else:\n",
    "            if np.argmax(ground_truth_label[Gini_indexs[i]]) != np.argmax(predicted_confidence[Gini_indexs[i]]):\n",
    "                o_i = o_i+1\n",
    "                wrong_num = wrong_num+1\n",
    "                pre_y_axis.append(o_i)\n",
    "            else:\n",
    "                pre_y_axis.append(o_i)\n",
    "    true_y_axis = wrong_num*(len(Gini_indexs)-wrong_num) + (wrong_num+1)*wrong_num/2\n",
    "    RAUC = np.sum(pre_y_axis)/true_y_axis\n",
    "#     print(\"RAUC: \", RAUC)\n",
    "    return RAUC, len(Gini_indexs), wrong_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6056c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size=(299, 299)):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def get_gradients(img_input, model, top_pred_idx):\n",
    "    \"\"\"Computes the gradients of outputs w.r.t input image.\n",
    "\n",
    "    Args:\n",
    "        img_input: 4D image tensor\n",
    "        top_pred_idx: Predicted label for the input image\n",
    "\n",
    "    Returns:\n",
    "        Gradients of the predictions w.r.t img_input\n",
    "    \"\"\"\n",
    "    images = tf.cast(img_input, tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        preds = model(images)\n",
    "        top_class = preds[:, top_pred_idx]\n",
    "\n",
    "    grads = tape.gradient(top_class, images)\n",
    "    return grads\n",
    "\n",
    "\n",
    "def get_integrated_gradients(img_input, model, top_pred_idx, baseline=None, num_steps=50):\n",
    "    \"\"\"Computes Integrated Gradients for a predicted label.\n",
    "\n",
    "    Args:\n",
    "        img_input (ndarray): Original image\n",
    "        top_pred_idx: Predicted label for the input image\n",
    "        baseline (ndarray): The baseline image to start with for interpolation\n",
    "        num_steps: Number of interpolation steps between the baseline\n",
    "            and the input used in the computation of integrated gradients. These\n",
    "            steps along determine the integral approximation error. By default,\n",
    "            num_steps is set to 50.\n",
    "\n",
    "    Returns:\n",
    "        Integrated gradients w.r.t input image\n",
    "    \"\"\"\n",
    "    # If baseline is not provided, start with a black image\n",
    "    # having same size as the input image.\n",
    "    if baseline is None:\n",
    "        baseline = np.zeros(img_size).astype(np.float32)\n",
    "    else:\n",
    "        baseline = baseline.astype(np.float32)\n",
    "\n",
    "    # 1. Do interpolation.\n",
    "    img_input = img_input.astype(np.float32)\n",
    "    interpolated_image = [\n",
    "        baseline + (step / num_steps) * (img_input - baseline)\n",
    "        for step in range(num_steps + 1)\n",
    "    ]\n",
    "    interpolated_image = np.array(interpolated_image).astype(np.float32)\n",
    "\n",
    "    # 2. Preprocess the interpolated images\n",
    "#     interpolated_image = model.preprocess_input(interpolated_image)\n",
    "\n",
    "    # 3. Get the gradients\n",
    "    grads = []\n",
    "    for i, img in enumerate(interpolated_image):\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        grad = get_gradients(img, model, top_pred_idx=top_pred_idx)\n",
    "        grads.append(grad[0])\n",
    "    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n",
    "\n",
    "    # 4. Approximate the integral using the trapezoidal rule\n",
    "    grads_tmp = (grads[:-1] + grads[1:]) / 2.0\n",
    "    avg_grads = tf.reduce_mean(grads_tmp, axis=0)\n",
    "\n",
    "    # 5. Calculate integrated gradients and return\n",
    "    integrated_grads = (img_input - baseline) * avg_grads\n",
    "    return integrated_grads, grads, avg_grads\n",
    "\n",
    "\n",
    "def random_baseline_integrated_gradients(\n",
    "    img_input, model, top_pred_idx, num_steps=50, num_runs=2\n",
    "):\n",
    "    \"\"\"Generates a number of random baseline images.\n",
    "\n",
    "    Args:\n",
    "        img_input (ndarray): 3D image\n",
    "        top_pred_idx: Predicted label for the input image\n",
    "        num_steps: Number of interpolation steps between the baseline\n",
    "            and the input used in the computation of integrated gradients. These\n",
    "            steps along determine the integral approximation error. By default,\n",
    "            num_steps is set to 50.\n",
    "        num_runs: number of baseline images to generate\n",
    "\n",
    "    Returns:\n",
    "        Averaged integrated gradients for `num_runs` baseline images\n",
    "    \"\"\"\n",
    "    # 1. List to keep track of Integrated Gradients (IG) for all the images\n",
    "    integrated_grads = []\n",
    "\n",
    "    # 2. Get the integrated gradients for all the baselines\n",
    "    for run in range(num_runs):\n",
    "        baseline = np.random.random(img_size) * 255\n",
    "        igrads, grads, avg_grads = get_integrated_gradients(\n",
    "            img_input=img_input,\n",
    "            top_pred_idx=top_pred_idx,\n",
    "            baseline=baseline,\n",
    "            num_steps=num_steps,\n",
    "        )\n",
    "        integrated_grads.append(igrads)\n",
    "\n",
    "    # 3. Return the average integrated gradients for the image\n",
    "    integrated_grads = tf.convert_to_tensor(integrated_grads)\n",
    "    return tf.reduce_mean(integrated_grads, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a62ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfile_name(file_dir):   \n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        return files\n",
    "#          print(root) #当前目录路径  \n",
    "#          print(dirs) #当前路径下所有子目录  \n",
    "#          print(files) #当前路径下所有非目录子文件 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258f8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/public/liujiawei/huawei/ZHB/ADF-master/datasets/ImageNetVal/'\n",
    "file_name = getfile_name(DATA_PATH)\n",
    "file_name = np.sort(file_name)\n",
    "\n",
    "f = open(\"/public/liujiawei/huawei/ZHB/ADF-master/datasets/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt\",encoding = \"utf-8\")\n",
    "val_ground_truth = f.read()\n",
    "val_ground_truth = val_ground_truth.split('\\n')\n",
    "for i in range(len(val_ground_truth)-1):\n",
    "    val_ground_truth[i] = int(val_ground_truth[i])\n",
    "\n",
    "    \n",
    "vgg19_json = json.load(open('/public/liujiawei/.keras/models/imagenet_class_index.json','r',encoding=\"utf-8\"))\n",
    "# numbers = []\n",
    "# with open('/public/liujiawei/huawei/ZHB/ADF-master/datasets/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         numbers.extend([int(num)\n",
    "#                        for num in line.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340779b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILSVRC2012_val_00000001.JPEG\n",
      "False\n",
      "(50000,)\n",
      "['ILSVRC2012_val_00001000.JPEG' 'ILSVRC2012_val_00001001.JPEG'\n",
      " 'ILSVRC2012_val_00001002.JPEG' 'ILSVRC2012_val_00001003.JPEG'\n",
      " 'ILSVRC2012_val_00001004.JPEG' 'ILSVRC2012_val_00001005.JPEG'\n",
      " 'ILSVRC2012_val_00001006.JPEG' 'ILSVRC2012_val_00001007.JPEG'\n",
      " 'ILSVRC2012_val_00001008.JPEG']\n"
     ]
    }
   ],
   "source": [
    "print((file_name[0]))\n",
    "label_tmp = file_name[0][-13:-5]\n",
    "# label_tmp = int(label_tmp)+1.0\n",
    "print((label_tmp=='00013979'))\n",
    "print(np.shape(file_name))\n",
    "print(np.sort(file_name)[999:1008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b47a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gpuinfo import GPUInfo\n",
    "\n",
    "# def get_gpu_id(num_gpu=1):\n",
    "#     \"\"\"get ID of GPUS\n",
    "#     :param num_gpu:  num of GPUs to use\n",
    "#     :return: gpu_id: ID of allocated GPUs\n",
    "#     \"\"\"\n",
    "#     available_device=GPUInfo.check_empty()\n",
    "#     if len(available_device)>=num_gpu:\n",
    "#         gpu_id = available_device[:num_gpu]\n",
    "#     else:\n",
    "#         raise Exception('Only {} GPUs to use!'.format(len(available_device)))\n",
    "#     if num_gpu == 1:\n",
    "#         gpu_id = gpu_id[0]\n",
    "\n",
    "\n",
    "#     return gpu_id\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# config=tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "# sess=tf.compat.v1.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d6a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdce5da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n04263257\n",
      "soup bowl\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "\n",
    "synsets = scipy.io.loadmat(os.path.join('/public/liujiawei/huawei/ZHB/ADF-master/datasets', 'ILSVRC2012_devkit_t12', 'data', 'meta.mat'))['synsets']\n",
    "# print(len(synsets))\n",
    "# print(synsets)\n",
    "\n",
    "ILSVRC2012_ID = [s[0][0][0][0] for s in synsets]\n",
    "# print(ILSVRC2012_ID)\n",
    "\n",
    "index1 = 821\n",
    "WNID = [s[0][1][0] for s in synsets]\n",
    "print(WNID[index1])\n",
    "\n",
    "words = [s[0][2][0] for s in synsets]\n",
    "print(words[index1])\n",
    "\n",
    "num_train_images = [s[0][7][0][0] for s in synsets]\n",
    "print(num_train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b25b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62673669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c66160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_num = range(0,1000) # 设置使用的样本数量和位置\n",
    "# pbar = ProgressBar()\n",
    "# acc = 0\n",
    "# for i in pbar(img_num):\n",
    "# #     print(file_name[i])\n",
    "#     img_path = DATA_PATH + file_name[i]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "#     y_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "# #     print(WNID[val_ground_truth[i]])\n",
    "# # *********************注意这里的 WNID 的索引需要“-1”*************************\n",
    "#     acc = acc + get_acc(predict_label=decode_predictions(y_tmp, top=1), ground_truth=WNID[val_ground_truth[i]-1])\n",
    "# #     if decode_predictions(y_tmp, top=3)[0][0][0] == WNID[val_ground_truth[i]]:\n",
    "# #         acc = acc+1\n",
    "    \n",
    "# print(\"The number of right classified:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a7a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_num = range(0,10)\n",
    "# pbar = ProgressBar()\n",
    "# for i in pbar(img_num):\n",
    "#     print(WNID[val_ground_truth[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f19935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(decode_predictions(y_tmp, top=4)[0][3][0])  ## 第一维的[0]是固定的，第二维的[i]表示第top(i+1)，第三维的[0]表示标签、[1]表示标签的真实名字、[2]表示标签的对应置信度\n",
    "# print(decode_predictions(y_tmp, top=4)[0][3][1])\n",
    "# print(decode_predictions(y_tmp, top=4)[0][3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2721948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n02437616'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNID[val_ground_truth[i]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbd7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_acc(predict_label=decode_predictions(y_tmp, top=3), ground_truth=WNID[val_ground_truth[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4bf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbar = ProgressBar()\n",
    "# tmp_train = [cv2.resize(i,(224,224)) for i in pbar(X_train)]\n",
    "# pbar = ProgressBar()\n",
    "# tmp_test = [cv2.resize(i,(224,224)) for i in pbar(X_test)]\n",
    "# ## 重新转回为 array\n",
    "# # tmp_train = np.array(tmp_train)\n",
    "# # tmp_test = np.array(tmp_test)\n",
    "\n",
    "# print(len(tmp_train))\n",
    "# print(np.shape(tmp_train[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fce3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keras 的图像处理操作\n",
    "# img_path = 'zebra.png'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "# y1 = base_model.predict(np.reshape(img, [-1,224,224,3]))\n",
    "# print(np.argmax(y1))\n",
    "\n",
    "# # keras 预训练模型的标签解释器\n",
    "# print('Predicted:', decode_predictions(y1, top=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7bd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(111)\n",
    "# plt.imshow(np.reshape(x, [224,224,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f419fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "60cf557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini = []\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "top_set = 1 # 预测的前n个类中包含真实标签则表示预测正确\n",
    "img_num = range(0, 1000)\n",
    "num_class = 1000\n",
    "ground_truth_label = []\n",
    "predicted_confidence = []\n",
    "# advrage_confidence = np.ones((1,num_class))*(1.0/(num_class-1))\n",
    "# advrage_confidence = np.zeros((1,num_class))\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(img_num):\n",
    "    img_path = DATA_PATH + file_name[i]\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x_tmp = image.img_to_array(img)\n",
    "    x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "    x_tmp = preprocess_input(x_tmp)\n",
    "    pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "    \n",
    "    Gini_tmp = 1-np.sum(pre_tmp*pre_tmp)  # 基于基尼指数\n",
    "#     Gini_tmp = -np.sum(pre_tmp*np.log(pre_tmp))  # 基于信息熵\n",
    "#     advrage_confidence[0][np.argmax(pre_tmp)] = 1\n",
    "#     Gini_tmp = -np.sum(advrage_confidence*np.log(pre_tmp))  # 基于交叉熵/反交叉熵\n",
    "    Gini.append(Gini_tmp)\n",
    "    \n",
    "#     index2 = index2 + get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), ground_truth=WNID[val_ground_truth[i]-1])\n",
    "#     index1 = index1 + 1\n",
    "    predicted_confidence.append(pre_tmp)\n",
    "    ground_truth_label.append(WNID[val_ground_truth[i]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "029ebacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('test number:', index1, '\\t misclassified number:', index1-index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f50864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019ead5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "7497d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.7350498575498575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(Gini)\n",
    "indexs = indexs[::-1]\n",
    "# # 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"APFD: \", APFD)\n",
    "# o_i = 0\n",
    "# pbar = ProgressBar()\n",
    "# # for i in pbar(range(0, (index1-index2))):\n",
    "# for i in (range(0, index1)):\n",
    "#     img_path = DATA_PATH + file_name[indexs[i]]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "#     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "#     if not get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), ground_truth=WNID[val_ground_truth[indexs[i]]-1]):\n",
    "#         o_i = o_i+i\n",
    "#         print(i, o_i)\n",
    "# APFD = 1-o_i/(index1*(index1-index2))+1/(2*index1)\n",
    "# print(\"APFD: \", APFD, o_i, index1, index1-index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af257ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9788ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前200个样本\n",
    "APFD:  0.901875  #基于基尼指数\n",
    "APFD:  0.8989062499999999    # 基于信息熵\n",
    "    \n",
    "# 前10000个样本\n",
    "APFD:  0.8936016026566561   #基于基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1045129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAUC:  0.890363463696797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"RAUC: \", RAUC)\n",
    "# true_y_axis = []\n",
    "# pre_y_axis = []\n",
    "# o_i = 0\n",
    "# pbar = ProgressBar()\n",
    "# for i in pbar(range(0, index1)):\n",
    "#     img_path = DATA_PATH + file_name[indexs[i]]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "#     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "#     if not get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), ground_truth=WNID[val_ground_truth[indexs[i]]-1]):\n",
    "#         o_i = o_i+1\n",
    "#         pre_y_axis.append(o_i)\n",
    "#     else:\n",
    "#         pre_y_axis.append(o_i)\n",
    "#     if i < index1-index2:\n",
    "#         true_y_axis.append(i+1)\n",
    "#     else:\n",
    "#         true_y_axis.append(index1-index2)\n",
    "            \n",
    "# RAUC = np.sum(pre_y_axis)/np.sum(true_y_axis)\n",
    "# print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1265a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43982d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# # 使用中间隐层特征计算基尼指数/信息熵\n",
    "# from tensorflow.keras import backend as BE\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
    "# Gini_act=[]\n",
    "# pbar = ProgressBar()\n",
    "# for i in pbar(img_num):\n",
    "#     img_path = DATA_PATH + file_name[i]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "    \n",
    "# #     # 使用attention机制\n",
    "# #     x_act = model.predict(x_tmp.reshape([-1,224,224,3]))\n",
    "# #     att1 = np.dot(np.transpose(x_act), x_act)\n",
    "# #     att_weight = np.mean(att1, axis = 0).reshape(np.shape(x_act))\n",
    "# #     x_act_ = softmax(x_act)*softmax(att_weight)\n",
    "# # #     Gini_tmp = 1-np.sum(x_act_*x_act_)  # 基于基尼指数\n",
    "# #     Gini_tmp = 1-np.sum(x_act_*np.log(x_act_))  # 基于信息熵\n",
    "# #     Gini_act.append(Gini_tmp)\n",
    "    \n",
    "#     #  未使用attention机制\n",
    "#     x_act = softmax(model.predict(np.reshape(x_tmp, [-1,224,224,3])))\n",
    "#     Gini_tmp = 1-np.sum(x_act*x_act)  # 基于基尼指数\n",
    "# #     Gini_tmp = 1-np.sum(x_act*np.log(x_act))  # 基于信息熵\n",
    "#     Gini_act.append(Gini_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f46bf9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# # 使用梯度信息\n",
    "# Gini_act = []\n",
    "# num_class = 1000\n",
    "# img_size = (224,224,3)\n",
    "# # img_num = range(0,250)\n",
    "# pbar = ProgressBar()\n",
    "\n",
    "# for i in pbar(img_num):\n",
    "    \n",
    "#     img_path = DATA_PATH + file_name[i]\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x_tmp = image.img_to_array(img)\n",
    "#     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "#     x_tmp = preprocess_input(x_tmp)\n",
    "#     preds = base_model.predict(x_tmp)\n",
    "    \n",
    "# #     使用真实标签验证\n",
    "# #     for j1 in range(1000):\n",
    "# #         if vgg19_json[str(j1)][0] == WNID[val_ground_truth[i]-1]:\n",
    "# #             break\n",
    "# #     grads = get_loss_gradients(img_input=x_tmp, model=base_model, \n",
    "# #                                target_one_hot=np.reshape(to_categorical(j1, 1000),(-1,1000)))\n",
    "    \n",
    "# #     使用预测标签当做真实标签验证\n",
    "#     model_ = Model(inputs=model.input, outputs=base_model.get_layer('fc2').output)\n",
    "#     hidden_layer = model_.predict(x_tmp)\n",
    "#     dim1 = len(hidden_layer[0])\n",
    "#     target_one_hot_ave = np.zeros([1, dim1]) * (1.0/dim1)\n",
    "#     target_one_hot_ave[0][np.argmax(hidden_layer[0])] = 1\n",
    "#     target_one_hot_ave = target_one_hot_ave * hidden_layer\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=model_, \n",
    "#                                target_one_hot=target_one_hot_ave, from_logits=False)\n",
    "    \n",
    "# #     label1 = np.argmax(preds[0])\n",
    "# #     target_one_hot = np.reshape(to_categorical(label1, num_class), (-1, num_class))\n",
    "# #     grads = get_loss_gradients(img_input=x_tmp, model=base_model, \n",
    "# #                                target_one_hot=target_one_hot)\n",
    "\n",
    "# #     grads = np.clip(grads, 0, 1)\n",
    "# #     preds[0][label1] = -1\n",
    "# #     label2 = np.argmax(preds[0])\n",
    "# #     grads2 = get_loss_gradients(img_input=x_tmp, model=base_model, \n",
    "# #                                target_one_hot=target_one_hot)\n",
    "\n",
    "#     x_act = np.sum(np.abs(grads))\n",
    "# #     if np.sum(np.abs(grads))>np.sum(np.abs(grads2)):\n",
    "# #         x_act = 1\n",
    "# #     else:\n",
    "# #         x_act=2\n",
    "        \n",
    "# #     grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=tf.argmax(preds[0]))\n",
    "# #     preds[0][tf.argmax(preds[0])] = -1\n",
    "# #     grads2 = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=tf.argmax(preds[0]))\n",
    "# #     if np.sum(np.abs(grads))>np.sum(np.abs(grads2)):\n",
    "# #         x_act = 1\n",
    "# #     else:\n",
    "# #         x_act=2\n",
    "    \n",
    "# #     grads = np.clip(grads, -1, 0)\n",
    "# #     grads2 = np.clip(grads2, -1, 0)\n",
    "# #     x_act = np.sum(np.abs(grads)) - np.sum(np.abs(grads2))\n",
    "# #     grads_min = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=tf.argmin(preds[0]))\n",
    "# #     x_act = np.sum(np.abs(grads)) * np.sum(np.abs(grads_min))\n",
    "\n",
    "\n",
    "\n",
    "# #     preds = base_model.predict(x_tmp)\n",
    "# # #     grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=tf.argmax(preds[0]))\n",
    "# #     integrated_grads, grads, avg_grads = get_integrated_gradients(img_input=x_tmp[0], model=base_model, top_pred_idx=tf.argmax(preds[0]), num_steps=2)\n",
    "# #     x_act = np.sum(np.abs(grads[2]))+np.sum(np.abs(grads[0]))\n",
    "# #     print(np.sum(np.abs(grads[2])),np.sum(np.abs(grads[1])),np.sum(np.abs(grads[0])),np.sum(np.abs(avg_grads)))\n",
    "# # #     grads_min = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=tf.argmin(preds[0]))\n",
    "# # #     x_act = np.sum(np.abs(grads)) * np.sum(np.abs(grads_min))\n",
    "    \n",
    "# #     pbar = ProgressBar()\n",
    "# #     x_act = []\n",
    "# #     for label_i in pbar(range(num_class)):\n",
    "# #         grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=label_i)\n",
    "# # #         grads = get_integrated_gradients(img_input=x_tmp, model=base_model, top_pred_idx=label_i)\n",
    "# #         x_act.append(np.sum(grads))\n",
    "# #     x_act = np.array(x_act).reshape(-1, num_class)\n",
    "# #     x_act = softmax(x_act)\n",
    "    \n",
    "# #     Gini_tmp = 1-np.sum(x_act*x_act)   \n",
    "#     Gini_act.append(x_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "9dfc2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# 使用梯度信息\n",
    "# img_num = range(0, 250)\n",
    "# Gini_act = []\n",
    "num_class = 1000\n",
    "img_size = (224,224,3)\n",
    "pbar = ProgressBar()\n",
    "\n",
    "# grads_CE = []\n",
    "# grads_RCE = []\n",
    "# grads_pre1 = []\n",
    "# grads_pre2 = []\n",
    "# grads_pre_min = []\n",
    "# grads_CE_ave = []\n",
    "# grads_CE_min = []\n",
    "# grads_CE2 = []\n",
    "\n",
    "grads_CE_positive = []\n",
    "grads_CE_negtive = []\n",
    "\n",
    "for i in pbar(img_num):\n",
    "    \n",
    "    img_path = DATA_PATH + file_name[i]\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x_tmp = image.img_to_array(img)\n",
    "    x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "    x_tmp = preprocess_input(x_tmp)\n",
    "    preds = base_model.predict(x_tmp)\n",
    "    \n",
    "#     使用预测标签当做真实标签验证\n",
    "    label1 = np.argmax(preds[0])\n",
    "    target_one_hot = preds\n",
    "    target_one_hot[0][label1] = 1\n",
    "    grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "    grads_CE_positive.append(grads)\n",
    "    \n",
    "    target_one_hot = preds\n",
    "    target_one_hot[0][label1] = 0\n",
    "    grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "    grads_CE_negtive.append(grads)\n",
    "\n",
    "#     label1 = np.argmax(preds[0])\n",
    "#     target_one_hot = np.reshape(to_categorical(label1, num_class), (-1, num_class))\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "#     grads_CE.append(grads)\n",
    "    \n",
    "#     label1_min = np.argmin(preds[0])\n",
    "#     target_one_hot = np.reshape(to_categorical(label1_min, num_class), (-1, num_class))\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "#     grads_CE_min.append(grads)\n",
    "    \n",
    "#     grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=label1_min)\n",
    "#     grads_pre_min.append(grads)\n",
    "    \n",
    "#     target_one_hot = np.ones([1, num_class]) * (1.0/(num_class-1))\n",
    "#     target_one_hot[0][label1] = 0\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "#     grads_RCE.append(grads)\n",
    "    \n",
    "#     target_one_hot = np.ones([1, num_class]) * (1.0/(num_class))\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "#     grads_CE_ave.append(grads)\n",
    "    \n",
    "#     grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=label1)\n",
    "#     grads_pre1.append(grads)\n",
    "    \n",
    "#     preds[0][label1] = 0\n",
    "#     label2 = np.argmax(preds[0])\n",
    "#     grads = get_gradients(img_input=x_tmp, model=base_model, top_pred_idx=label2)\n",
    "#     grads_pre2.append(grads)\n",
    "    \n",
    "#     target_one_hot = np.reshape(to_categorical(label2, num_class), (-1, num_class))\n",
    "#     grads = get_loss_gradients(img_input=x_tmp, model=base_model, target_one_hot=target_one_hot)\n",
    "#     grads_CE2.append(grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "fe10d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.6904088319088318 351\n",
      "RAUC:  0.8362531295864629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Gini_act_ =[]\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(len(grads_CE_positive))):\n",
    "#     x_act = np.sum(np.abs(grads_CE[i]))\n",
    "    x_act =[np.sum(np.abs(grads_CE_positive[i])),\n",
    "            np.sum(np.abs(grads_CE_negtive[i])),\n",
    "           ]\n",
    "#     print(i,':',x_act)\n",
    "    Gini_act_.append(x_act)\n",
    "    \n",
    "Gini_act_ = np.array(Gini_act_)\n",
    "indexs = np.argsort(Gini_act_[:,1]/Gini_act_[:,0])\n",
    "# print(indexs)\n",
    "indexs = indexs[::-1]\n",
    "# print(indexs)\n",
    "APFD,wrong_number,wrong_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"APFD: \", APFD, wrong_number)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ac638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a4701711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3869915 11.189025 11.174898 2.115178 2.8073308\n",
      "2.4294407 17.323147 17.304945 1.8713104 1.8632013\n",
      "2.875944 11.7236 11.711569 1.4050138 1.4200213\n",
      "5.270518 11.276661 11.262339 2.0938423 1.1635923\n",
      "2.7589445 22.305952 22.282848 1.2901204 1.3552691\n",
      "3.7819545 8.438682 8.427843 1.1134738 0.5739374\n",
      "0.6285847 19.955963 19.935661 0.5863522 0.4647086\n",
      "7.466598 12.038355 12.022115 4.387728 2.2807024\n",
      "8.709082 5.83937 5.829669 2.57412 1.7856172\n",
      "3.950269 34.457554 34.420277 3.4191606 1.767835\n",
      "*******************************************************\n",
      "695.92035 3611.6404 3607.7095 294.23935 189.24251\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.sum(np.abs(grads_CE[i])),np.sum(np.abs(grads_RCE[i])),np.sum(np.abs(grads_CE_ave[i])),\n",
    "      np.sum(np.abs(grads_pre1[i])),np.sum(np.abs(grads_pre2[i])))\n",
    "print('*******************************************************')\n",
    "print(np.sum(np.abs(grads_CE)),np.sum(np.abs(grads_RCE)),np.sum(np.abs(grads_CE_ave)),\n",
    "      np.sum(np.abs(grads_pre1)),np.sum(np.abs(grads_pre2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "30d268fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3) (1000, 1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(grads_CE),np.shape(grads_RCE),np.shape(grads_pre1),np.shape(grads_pre2),\n",
    "      np.shape(grads_pre_min),np.shape(grads_CE_ave),np.shape(grads_CE_min),np.shape(grads_CE2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "6d64c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini_act =[]\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(len(grads_CE))):\n",
    "#     x_act = np.sum(np.abs(grads_CE[i]))\n",
    "    x_act =[np.sum(np.abs(grads_CE[i])),\n",
    "            np.sum(np.abs(grads_CE2[i])),\n",
    "            np.sum(np.abs(grads_CE_min[i])),\n",
    "            np.sum(np.abs(grads_RCE[i])),\n",
    "            np.sum(np.abs(grads_CE_ave[i])),\n",
    "            np.sum(np.abs(grads_pre1[i])),\n",
    "            np.sum(np.abs(grads_pre2[i])),\n",
    "            np.sum(np.abs(grads_pre_min[i])),\n",
    "            np.std(grads_CE[i]),\n",
    "            np.std(grads_CE2[i]),\n",
    "            np.std(grads_CE_min[i]),\n",
    "            np.std(grads_RCE[i]),\n",
    "            np.std(grads_CE_ave[i]),\n",
    "            np.std(grads_pre1[i]),\n",
    "            np.std(grads_pre2[i]),\n",
    "            np.std(grads_pre_min[i]),\n",
    "           ]\n",
    "#     print(i,':',x_act)\n",
    "    Gini_act.append(x_act)\n",
    "    \n",
    "#     # attention 机制\n",
    "# for i in pbar(range(len(grads_CE))):\n",
    "# #     x_act = np.sum(np.abs(grads_CE[i]))\n",
    "#     x_act =[np.sum(np.abs(  [np.dot( np.transpose(grads_CE[i], (0,3,1,2))[0][0] , np.transpose(grads_CE[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_CE[i], (0,3,1,2))[0][1] , np.transpose(grads_CE[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_CE[i], (0,3,1,2))[0][2] , np.transpose(grads_CE[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_CE2[i], (0,3,1,2))[0][0] , np.transpose(grads_CE2[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_CE2[i], (0,3,1,2))[0][1] , np.transpose(grads_CE2[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_CE2[i], (0,3,1,2))[0][2] , np.transpose(grads_CE2[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_CE_min[i], (0,3,1,2))[0][0] , np.transpose(grads_CE_min[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_CE_min[i], (0,3,1,2))[0][1] , np.transpose(grads_CE_min[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_CE_min[i], (0,3,1,2))[0][2] , np.transpose(grads_CE_min[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_RCE[i], (0,3,1,2))[0][0] , np.transpose(grads_RCE[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_RCE[i], (0,3,1,2))[0][1] , np.transpose(grads_RCE[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_RCE[i], (0,3,1,2))[0][2] , np.transpose(grads_RCE[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_CE_ave[i], (0,3,1,2))[0][0] , np.transpose(grads_CE_ave[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_CE_ave[i], (0,3,1,2))[0][1] , np.transpose(grads_CE_ave[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_CE_ave[i], (0,3,1,2))[0][2] , np.transpose(grads_CE_ave[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_pre1[i], (0,3,1,2))[0][0] , np.transpose(grads_pre1[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_pre1[i], (0,3,1,2))[0][1] , np.transpose(grads_pre1[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_pre1[i], (0,3,1,2))[0][2] , np.transpose(grads_pre1[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_pre2[i], (0,3,1,2))[0][0] , np.transpose(grads_pre2[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_pre2[i], (0,3,1,2))[0][1] , np.transpose(grads_pre2[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_pre2[i], (0,3,1,2))[0][2] , np.transpose(grads_pre2[i], (0,3,2,1))[0][2])]  )),\n",
    "#             np.sum(np.abs(  [np.dot( np.transpose(grads_pre_min[i], (0,3,1,2))[0][0] , np.transpose(grads_pre_min[i], (0,3,2,1))[0][0]),\n",
    "#                              np.dot( np.transpose(grads_pre_min[i], (0,3,1,2))[0][1] , np.transpose(grads_pre_min[i], (0,3,2,1))[0][1]),\n",
    "#                              np.dot( np.transpose(grads_pre_min[i], (0,3,1,2))[0][2] , np.transpose(grads_pre_min[i], (0,3,2,1))[0][2])]  ))]\n",
    "# #     print(i,':',x_act)\n",
    "#     Gini_act.append(x_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e380d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "5dc01e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.7234487179487179 351\n",
      "RAUC:  0.8763014763014763\n"
     ]
    }
   ],
   "source": [
    "Gini_act = np.array(Gini_act)\n",
    "# indexs = np.argsort(np.sqrt(Gini_act[:,0]*Gini_act[:,0]+Gini_act[:,5]*Gini_act[:,5]+Gini_act[:,6]*Gini_act[:,6]+Gini_act[:,7]*Gini_act[:,7])/\n",
    "#                     np.sqrt(Gini_act[:,1]*Gini_act[:,1]+Gini_act[:,2]*Gini_act[:,2]+Gini_act[:,3]*Gini_act[:,3]+Gini_act[:,4]*Gini_act[:,4]))\n",
    "indexs = np.argsort(np.abs(Gini_act[:,0]/(np.abs(Gini_act[:,1]))))\n",
    "#                     np.sqrt(Gini_act[:,1]+Gini_act[:,2]+Gini_act[:,3]+Gini_act[:,4]))\n",
    "# print(indexs)\n",
    "indexs = indexs[::-1]\n",
    "# print(indexs)\n",
    "APFD,wrong_number,wrong_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"APFD: \", APFD, wrong_number)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "67ab3160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9121702e+00, 9.2403870e+00, 1.8496599e+01, 1.4295383e+01,\n",
       "       1.4279771e+01, 1.2114879e+00, 7.9420924e-01, 4.0131471e-07],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "ceb86fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.5732094017094016 351\n",
      "RAUC:  0.6941932141932142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Cluster_Gini_act = []\n",
    "\n",
    "for i in range(len(grads_CE)):\n",
    "    tmp1 = np.sqrt (np.sum( (data[i]-centers[0]) * (data[i]-centers[0]) ) )\n",
    "    tmp2 = np.sqrt (np.sum( (data[i]-centers[1]) * (data[i]-centers[1]) ) )\n",
    "    if (tmp1<tmp2):\n",
    "#         print(tmp1)\n",
    "        Cluster_Gini_act.append(tmp2)\n",
    "    else:\n",
    "        Cluster_Gini_act.append(1000000-tmp1)\n",
    "        \n",
    "indexs = np.argsort(Cluster_Gini_act)\n",
    "indexs = indexs[::-1]\n",
    "# print(indexs)\n",
    "APFD,wrong_number,wrong_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"APFD: \", APFD, wrong_number)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "799cd896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ground_truth_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "128ddae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans,AffinityPropagation, SpectralClustering\n",
    "\n",
    "# 读取数据\n",
    "data = np.array(Gini_act)\n",
    "# 聚类数量\n",
    "k = 2\n",
    "# 训练模型\n",
    "\n",
    "# model = AffinityPropagation(damping=0.5, max_iter=500, convergence_iter=30,\n",
    "#                          preference=-50).fit(data)\n",
    "# centers = model.cluster_centers_\n",
    "# result = model.labels_\n",
    "\n",
    "# model = SpectralClustering(gamma=0.1, n_clusters=2)\n",
    "# model.fit_predict(data)\n",
    "# # centers = model.cluster_centers_\n",
    "# result = model.labels_\n",
    "\n",
    "\n",
    "model = KMeans(n_clusters=k)\n",
    "model.fit(data)\n",
    "# 分类中心点坐标\n",
    "centers = model.cluster_centers_\n",
    "# 预测结果\n",
    "result = model.predict(data)\n",
    "\n",
    "\n",
    "# 用不同的颜色绘制数据点\n",
    "mark = ['or', 'og']\n",
    "for i, d in enumerate(data):\n",
    "    plt.plot(d[0], d[1], mark[ground_truth_cluster[i]])\n",
    "# 画出各个分类的中心点\n",
    "mark = ['*r', '*g']\n",
    "for i, center in enumerate(centers):\n",
    "    plt.plot(center[0], center[1], mark[i], markersize=20)\n",
    "\n",
    "# # 绘制簇的作用域\n",
    "# # 获取数据值所在的范围\n",
    "# x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "# y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "\n",
    "# # 生成网格矩阵\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "# z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# z = z.reshape(xx.shape)\n",
    "# cs = plt.contourf(xx, yy, z)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "3bcad01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centers = model.cluster_centers_\n",
    "result = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpectralClustering().fit_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpectralClustering().fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "b2f1b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1\n",
      " 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(1-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "bab86595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0\n",
      " 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
      " 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "ground_truth_cluster = np.zeros([len(result)], dtype=np.int32)\n",
    "ground_truth_cluster[wrong_index]=1\n",
    "print(ground_truth_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "8e96da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6524837034965916"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(np.sum(ground_truth_cluster&clf.predict(data)))\n",
    "# print(np.sum(ground_truth_cluster & (1-result)), np.sum(ground_truth_cluster), np.sum(1-result))\n",
    "\n",
    "clf.predict_proba(data[0].reshape(-1, 16))[0][1]\n",
    "# SVM_Gini_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "455558ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "819685a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector：\n",
      " [201 196]\n",
      "Score： 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "# 加载数据集\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = data  # 样本\n",
    "y = ground_truth_cluster  # 类别\n",
    "# 划分数据集\n",
    "X_trainer, X_test, Y_trainer, Y_test = model_selection.train_test_split(data, ground_truth_cluster, test_size=0.3)\n",
    "# 分类器\n",
    "# kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
    "clf = svm.SVC(kernel=\"rbf\", probability=True)   # 参数kernel为线性核函数\n",
    "clf.fit(X_trainer, Y_trainer)  # 训练分类器\n",
    "print(\"Support Vector：\\n\", clf.n_support_)  # 每一类中属于支持向量的点数目\n",
    "# print(\"Predict：\\n\", clf.predict(X_test))  # 对测试集的预测结果\n",
    "score = clf.score(X_test, Y_test)  # 模型得分\n",
    "print(\"Score：\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "0a5e4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.7262464387464387 351\n",
      "RAUC:  0.8796926530259863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_Gini_act = []\n",
    "for data1 in data:\n",
    "    SVM_Gini_act.append(  clf.predict_proba(data1.reshape(-1, 16))[0][1]  )\n",
    "\n",
    "indexs = np.argsort(SVM_Gini_act)\n",
    "indexs = indexs[::-1]\n",
    "# print(indexs)\n",
    "APFD,wrong_number,wrong_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"APFD: \", APFD, wrong_number)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "                predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "print(\"RAUC: \", RAUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "47ec0ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "fa4ced1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ed4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af5331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "718df43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def get_loss_gradients(img_input, model, target_one_hot, from_logits=False):\n",
    "    images = tf.cast(img_input, tf.float32)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=from_logits)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        preds = model(images)\n",
    "        loss = cce(target_one_hot, preds)\n",
    "#         top_class = preds[:, top_pred_idx]\n",
    "\n",
    "    grads = tape.gradient(loss, images)\n",
    "    return grads\n",
    "\n",
    "# def get_loss_gradients_Layer(img_input, hidden_layer_input, model, target_one_hot, layer_name = None):\n",
    "#     images = tf.cast(img_input, tf.float32)\n",
    "#     hidden_layer_input = tf.cast(hidden_layer, tf.float32)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "#     if layer_name is not None:\n",
    "# #         model_layer = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(hidden_layer_input)\n",
    "#             preds = model(images)\n",
    "#             loss = cce(target_one_hot, preds)\n",
    "#     #         top_class = preds[:, top_pred_idx]\n",
    "#     else:\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(images)\n",
    "#             preds = model(images)\n",
    "#             loss = cce(target_one_hot, preds)\n",
    "#     grads = tape.gradient(loss, images)\n",
    "#     return grads\n",
    "\n",
    "# def get_loss_gradients_Layer(img_input, hidden_layer_input, model, target_one_hot, layer_name = None):\n",
    "#     images = tf.cast(img_input, tf.float32)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "#     if layer_name is not None:\n",
    "#         model_layer = Model(inputs=hidden_layer_input, outputs=model.get_layer('fc2').output)\n",
    "#         hidden_layer = tf.cast(hidden_layer_input, tf.float32)\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(hidden_layer)\n",
    "#             preds = model_layer(hidden_layer)\n",
    "#             print(np.shape(preds), np.sum(preds))\n",
    "#             loss = cce(target_one_hot, preds)\n",
    "#     #         top_class = preds[:, top_pred_idx]\n",
    "#     else:\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(images)\n",
    "#             preds = model(images)\n",
    "#             loss = cce(target_one_hot, preds)\n",
    "#     grads = tape.gradient(loss, images)\n",
    "#     return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fed18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8685734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# 对中间隐层特征进行分级，计算基尼指数/信息熵\n",
    "from tensorflow.keras import backend as BE\n",
    "\n",
    "num_class = 100\n",
    "# img_num = range(0,10)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "Gini_act=[]\n",
    "# ground_truth_label = []\n",
    "# predicted_confidence = []\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(img_num):\n",
    "    img_path = DATA_PATH + file_name[i]\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x_tmp = image.img_to_array(img)\n",
    "    x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "    x_tmp = preprocess_input(x_tmp)\n",
    "    \n",
    "    #  使用分组机制\n",
    "#     x_act = softmax(model.predict(np.reshape(x_tmp, [-1,224,224,3])))\n",
    "    x_act = model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "    mu = np.average(x_act[0])\n",
    "    sigma = np.std(x_act[0])\n",
    "    x_act[0] = (x_act[0] - mu) / sigma\n",
    "    \n",
    "    # attention机制\n",
    "    att1 = np.dot(np.transpose(x_act), x_act)\n",
    "    att_weight = np.mean(att1, axis = 0).reshape(np.shape(x_act))\n",
    "    x_act = x_act*att_weight\n",
    "\n",
    "    x_act_sorted = np.sort(x_act[0])[::-1]  # 对x_act进行从大到小排序\n",
    "    group1 = int(np.shape(x_act)[1]/num_class)\n",
    "    if group1<1:\n",
    "        break\n",
    "    vect1 = np.zeros((1, num_class))\n",
    "    x_act_sorted = np.sort(x_act[0])[::-1]\n",
    "    for j in range(0, num_class-1):\n",
    "        vect1[0][j] = np.sum(x_act_sorted[j*group1:(j+1)*group1])\n",
    "    vect1[0][-1] = np.sum(x_act_sorted[num_class*group1:-1])\n",
    "\n",
    "    Gini_tmp = 1-np.sum(vect1*vect1)  # 基于基尼指数\n",
    "#     Gini_tmp = -np.sum(x_act*np.log(x_act))  # 基于信息熵\n",
    "    Gini_act.append(Gini_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887003ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af6c6e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d95ed4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fac00030f60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(grads[0])\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(igrads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141170bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "69ab7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.48671428571428577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# indexs = np.argsort(Gini_act)\n",
    "# indexs = indexs[::-1]\n",
    "# APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "#                 predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "# print(\"APFD: \", APFD)\n",
    "# # o_i = 0\n",
    "# # pbar = ProgressBar()\n",
    "# # for i in pbar(range(0, index1)):\n",
    "# # # for i in range(0, index1):\n",
    "# #     img_path = DATA_PATH + file_name[indexs[i]]\n",
    "# #     img = image.load_img(img_path, target_size=(224, 224))\n",
    "# #     x_tmp = image.img_to_array(img)\n",
    "# #     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "# #     x_tmp = preprocess_input(x_tmp)\n",
    "# #     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "# #     if not get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), ground_truth=WNID[val_ground_truth[indexs[i]]-1]):\n",
    "# #         o_i = o_i+i\n",
    "# # #         print(i,o_i)\n",
    "# # APFD = 1-o_i/(index1*(index1-index2))+1/(2*index1)\n",
    "# # print(\"APFD: \", APFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ae444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d156d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 前200个样本\n",
    "# APFD:  0.9518749999999999 # 未使用attention机制，fc2层特征，基于基尼指数\n",
    "# APFD:  0.9358593749999999    # 未使用attention机制，fc2层特征，基于信息熵\n",
    "# APFD:  0.943359375   # 使用attention机制，fc2层特征，基于基尼指数\n",
    "# APFD:  0.9811718749999999 # 使用attention机制，fc2层特征，基于信息熵\n",
    "# # 前10000个样本\n",
    "# APFD:  0.961101140629512    # 使用attention机制，fc2层特征，基于信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a81cba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAUC:  0.5803786574870913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 计算RAUC指标\n",
    "# RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label), \n",
    "#                 predicted_confidence=np.array(predicted_confidence), top_set=top_set)\n",
    "# print(\"RAUC: \", RAUC)\n",
    "\n",
    "# # true_y_axis = []\n",
    "# # pre_y_axis = []\n",
    "# # o_i = 0\n",
    "# # pbar = ProgressBar()\n",
    "# # for i in pbar(range(0, index1)):\n",
    "# #     img_path = DATA_PATH + file_name[indexs[i]]\n",
    "# #     img = image.load_img(img_path, target_size=(224, 224))\n",
    "# #     x_tmp = image.img_to_array(img)\n",
    "# #     x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "# #     x_tmp = preprocess_input(x_tmp)\n",
    "# #     pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,224,224,3]))\n",
    "# #     if not get_acc(predict_label=decode_predictions(pre_tmp, top=top_set), ground_truth=WNID[val_ground_truth[indexs[i]]-1]):\n",
    "# #         o_i = o_i+1\n",
    "# #         pre_y_axis.append(o_i)\n",
    "# #     else:\n",
    "# #         pre_y_axis.append(o_i)\n",
    "# #     if i < index1-index2:\n",
    "# #         true_y_axis.append(i+1)\n",
    "# #     else:\n",
    "# #         true_y_axis.append(index1-index2)\n",
    "            \n",
    "# # RAUC = np.sum(pre_y_axis)/np.sum(true_y_axis)\n",
    "# # print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0eabd1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n01751748'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNID[val_ground_truth[indexs[i]]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d0b6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8bfd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3053037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8dde85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n02640242'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51237732",
   "metadata": {},
   "outputs": [],
   "source": [
    "n02640242"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
