{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e7ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from art.utils import load_mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from art.metrics.metrics import empirical_robustness, clever_t, clever_u, clever, loss_sensitivity, wasserstein_distance\n",
    "import numpy as np\n",
    "from art.estimators.classification.keras import KerasClassifier\n",
    "import logging\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3164cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_L1 = 40\n",
    "R_L2 = 2\n",
    "R_LI = 0.1\n",
    "\n",
    "def _create_krclassifier_FMNIST():\n",
    "    num_classes = 10\n",
    "    input_shape = (28,28,1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', name = 'block1_conv1', \n",
    "                     input_shape=input_shape))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn1'))\n",
    "    model.add(Activation('relu', name = 'block1_act1'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool1'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', name = 'block1_conv2'))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn2'))\n",
    "    model.add(Activation('relu', name = 'block1_act2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool2'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', name = 'block1_conv3'))\n",
    "    # model.add(BatchNormalization(name = 'block1_bn3'))\n",
    "    model.add(Activation('relu', name = 'block1_act3'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool3'))\n",
    "    # top\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "    model.add(Dropout(0.5, name='drop1'))\n",
    "    model.add(Dense(32, activation='relu', name='fc2'))\n",
    "    model.add(Dropout(0.5, name='drop2'))\n",
    "    # model.add(Dense(64, activation='relu', name='fc3'))\n",
    "    # model.add(Dropout(0.5, name='drop3'))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "    \n",
    "    # model = load_model(\"./fmnist_CNN.h5\")\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Get the classifier\n",
    "    krc = KerasClassifier(model=model, clip_values=(0, 1), use_logits=False)\n",
    "\n",
    "    return krc\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25b4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test), _, _ = load_mnist()\n",
    "\n",
    "# Get the classifier\n",
    "# krc = _create_krclassifier_FMNIST()\n",
    "# krc.fit(x_train, y_train, batch_size=256, nb_epochs=5, shuffle=True,\n",
    "#         validation_data=(x_test[0:5000], y_test[0:5000]), verbose=1)\n",
    "\n",
    "krc = load_model('./fmnist_CNN_art.h5')\n",
    "krc = KerasClassifier(model=krc, clip_values=(0, 1), use_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435d80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# krc.save(filename='fmnist_CNN_art.h5', path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb48e9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/liujiawei/anaconda3/envs/ZHB_env/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# Gini = []\n",
    "# total_sample_num = 2000\n",
    "# predicted_confidence = []\n",
    "\n",
    "# pbar = ProgressBar()\n",
    "# for index in pbar(range(total_sample_num)):\n",
    "#     pre_tmp = krc.predict(np.reshape(x_test[index], [-1,28,28,1]))\n",
    "#     Gini.append(1-np.sum(pre_tmp*pre_tmp))\n",
    "#     predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad32943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.9419964788732395\n",
      "RAUC:  0.9585205891839587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# indexs = np.argsort(Gini)\n",
    "# indexs = indexs[::-1]\n",
    "# # 计算APFD指标\n",
    "# APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "#                    predicted_confidence=np.array(predicted_confidence))\n",
    "# print(\"APFD: \", APFD)\n",
    "\n",
    "# # 计算RAUC指标\n",
    "# RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "#                     predicted_confidence=np.array(predicted_confidence))\n",
    "# print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c1a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/liujiawei/anaconda3/envs/ZHB_env/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini = []\n",
    "total_sample_num = 2000\n",
    "predicted_confidence = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(total_sample_num)):\n",
    "    pre_tmp = krc.predict(np.reshape(x_test[index], [-1,28,28,1]))\n",
    "    Gini.append(\n",
    "        np.sqrt(\n",
    "            ( np.sum( (np.max(pre_tmp)-pre_tmp) * (np.max(pre_tmp)-pre_tmp) ) ) / len(pre_tmp[0])\n",
    "        )\n",
    "    )\n",
    "    predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31104f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.942637323943662\n",
      "RAUC:  0.9591728487976203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(Gini)\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86881556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# craft adversarial examples\n",
    "x_adv = []\n",
    "y_adv = []\n",
    "max_iter = 100\n",
    "eps = 50\n",
    "thre_conf = 0.5# 0.999999\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(100)):\n",
    "    pre_tmp = krc.predict(np.reshape(x_test[i], [-1,28,28,1]))\n",
    "    x_adv_tmp = np.copy(x_test[i])\n",
    "    # check whether x is right prediction\n",
    "    if np.argmax(pre_tmp[0]) == np.argmax(y_test[i]):\n",
    "        for j in range(max_iter):\n",
    "            grad_tmp = krc.class_gradient(np.reshape(x_adv_tmp, [-1,28,28,1]), \n",
    "                                                 label=np.argmax(y_test[i]))[0][0]\n",
    "            x_adv_tmp = x_adv_tmp - eps * grad_tmp\n",
    "            pre_adv_tmp = krc.predict(np.reshape(x_adv_tmp, [-1,28,28,1]))\n",
    "            if np.argmax(pre_adv_tmp[0]) != np.argmax(y_test[i]):\n",
    "                if np.max(pre_adv_tmp[0])>thre_conf:\n",
    "                    x_adv.append(x_adv_tmp)\n",
    "                    y_adv.append(y_test[i])\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f914718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# x_adv = np.array(x_adv)\n",
    "# y_adv = np.array(y_adv)\n",
    "# np.save('./x_adv.npy', x_adv)\n",
    "# np.save('./y_adv.npy', y_adv)\n",
    "x_adv = np.load('./x_adv.npy')\n",
    "y_adv = np.load('./y_adv.npy')\n",
    "print(x_adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d60bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv_clean = np.concatenate((x_adv, x_test[100:250]))\n",
    "Y_adv_clean = np.concatenate((y_adv, y_test[100:250]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c702cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "Gini_adv = []\n",
    "predicted_confidence = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(len(X_adv_clean))):\n",
    "    pre_tmp = krc.predict(np.reshape(X_adv_clean[index], [-1,28,28,1]))\n",
    "#     Gini_adv.append(\n",
    "#         np.sqrt(\n",
    "#             ( np.sum( (np.max(pre_tmp)-pre_tmp) * (np.max(pre_tmp)-pre_tmp) ) ) / len(pre_tmp[0])\n",
    "#         )\n",
    "#     )\n",
    "    Gini_adv.append(1-np.sum(pre_tmp*pre_tmp))\n",
    "    predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6cea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.20673400673400674\n",
      "RAUC:  0.21476748313809016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(Gini_adv)\n",
    "indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30fb05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# BoundaryGini = []\n",
    "# predicted_confidence = []\n",
    "\n",
    "# R_L1 = 40\n",
    "# R_L2 = 2\n",
    "# R_LI = 0.1\n",
    "# pbar = ProgressBar()\n",
    "# for index in pbar(range(len(X_adv_clean))):\n",
    "#     pre_tmp = krc.predict(np.reshape(X_adv_clean[index], [-1,28,28,1]))\n",
    "#     res_tmp = clever_u(krc, X_adv_clean[index], 10, 10, R_L2, norm=2, pool_factor=5, verbose=False)\n",
    "#     BoundaryGini.append(np.min([res_tmp, 2]))\n",
    "#     predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "590ff5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.6364102564102564\n",
      "RAUC:  0.7045977011494253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# indexs = np.argsort(BoundaryGini)\n",
    "# # indexs = indexs[::-1]\n",
    "# # 计算APFD指标\n",
    "# APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "#                    predicted_confidence=np.array(predicted_confidence))\n",
    "# print(\"APFD: \", APFD)\n",
    "\n",
    "# # 计算RAUC指标\n",
    "# RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "#                     predicted_confidence=np.array(predicted_confidence))\n",
    "# print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a0fb5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "BoundaryGini = []\n",
    "predicted_confidence = []\n",
    "\n",
    "R_L1 = 40\n",
    "R_L2 = 2\n",
    "R_LI = 0.1\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(len(X_adv_clean))):\n",
    "    pre_tmp = krc.predict(np.reshape(X_adv_clean[index], [-1,28,28,1]))\n",
    "#     res_tmp = clever_u(krc, X_adv_clean[index], 10, 10, R_L2, norm=2, pool_factor=5, verbose=False)\n",
    "#     BoundaryGini.append(np.min([res_tmp, 2]))\n",
    "    res_tmp = clever(krc, X_adv_clean[index], 10, 10, R_L2, norm=2, pool_factor=5, verbose=False)\n",
    "    BoundaryGini.append(\n",
    "        np.sqrt(\n",
    "            ( np.sum( (np.min(res_tmp)-res_tmp) * (np.min(res_tmp)-res_tmp) ) ) / len(res_tmp)\n",
    "        )\n",
    "    )\n",
    "    predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa67a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.5943589743589743\n",
      "RAUC:  0.6574712643678161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(BoundaryGini)\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7493c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "grad_Gini = []\n",
    "predicted_confidence = []\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(len(X_adv_clean))):\n",
    "    pre_tmp = krc.predict(np.reshape(X_adv_clean[index], [-1,28,28,1]))\n",
    "    grad_tmp = krc.class_gradient(np.reshape(X_adv_clean[index], [-1,28,28,1]), \n",
    "                                  label=np.argmax(pre_tmp[0]))[0][0]\n",
    "    grad_Gini.append(np.sum(np.abs(grad_tmp)))\n",
    "    predicted_confidence.append(pre_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a054dbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.13076923076923078\n",
      "RAUC:  0.13793103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(grad_Gini)\n",
    "indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=Y_adv_clean,\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f6dffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "R_L1 = 40\n",
    "R_L2 = 2\n",
    "R_LI = 0.05\n",
    "BoundaryGini2 = []\n",
    "\n",
    "pbar = ProgressBar()\n",
    "for index in pbar(range(len(X_adv_clean))):\n",
    "    pre_tmp = krc.predict(np.reshape(X_adv_clean[index], [-1,28,28,1]))\n",
    "    res_tmp = inverper_c(krc, X_adv_clean[index], 10, 10, R_L2, norm=np.inf, pool_factor=5, prob_constant=0.5)\n",
    "    BoundaryGini2.append(res_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34c12854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.5086694762191452\n",
      "RAUC:  0.9270051508462105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexs = np.argsort(BoundaryGini2)\n",
    "# indexs = np.argsort(np.abs(BoundaryGini2))\n",
    "# indexs = indexs[::-1]\n",
    "# 计算APFD指标\n",
    "APFD,_,_ = get_APFD(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                   predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"APFD: \", APFD)\n",
    "\n",
    "# 计算RAUC指标\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=y_test[range(total_sample_num)],\n",
    "                    predicted_confidence=np.array(predicted_confidence))\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52e133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f17488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from functools import reduce\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Union, TYPE_CHECKING\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy.optimize import fmin as scipy_optimizer\n",
    "from scipy.stats import weibull_min\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
    "from art.utils import random_sphere\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from art.attacks.attack import EvasionAttack\n",
    "    from art.utils import CLASSIFIER_TYPE, CLASSIFIER_LOSS_GRADIENTS_TYPE, CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE\n",
    "    \n",
    "def inverper_c(\n",
    "    classifier: \"CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE\",\n",
    "    x: np.ndarray,\n",
    "    nb_batches: int,\n",
    "    batch_size: int,\n",
    "    radius: float,\n",
    "    norm: float,\n",
    "    c_init: float = 1.0,\n",
    "    pool_factor: int = 10,\n",
    "    prob_constant: float = 0.05,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute CLEVER score for a targeted attack.\n",
    "\n",
    "    | Paper link: https://arxiv.org/abs/1801.10578\n",
    "\n",
    "    :param classifier: A trained model.\n",
    "    :param x: One input sample.\n",
    "    :param nb_batches: Number of repetitions of the estimate.\n",
    "    :param batch_size: Number of random examples to sample per batch.\n",
    "    :param radius: Radius of the maximum perturbation.\n",
    "    :param norm: Current support: 1, 2, np.inf.\n",
    "    :param c_init: Initialization of Weibull distribution.\n",
    "    :param pool_factor: The factor to create a pool of random samples with size pool_factor x n_s.\n",
    "    :return: CLEVER score.\n",
    "    \"\"\"\n",
    "    # Check if the targeted class is different from the predicted class\n",
    "    y_pred = classifier.predict(np.array([x]))\n",
    "    pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "\n",
    "    # Check if pool_factor is smaller than 1\n",
    "    if pool_factor < 1:  # pragma: no cover\n",
    "        raise ValueError(\"The `pool_factor` must be larger than 1.\")\n",
    "\n",
    "    # Some auxiliary vars\n",
    "    rand_pool_grad_set = []\n",
    "    grad_norm_set = []\n",
    "    dim = reduce(lambda x_, y: x_ * y, x.shape, 1)\n",
    "    shape = [pool_factor * batch_size]\n",
    "    shape.extend(x.shape)\n",
    "\n",
    "    # Generate a pool of samples\n",
    "    rand_pool = np.reshape(\n",
    "        random_sphere(nb_points=pool_factor * batch_size, nb_dims=dim, radius=radius, norm=norm),\n",
    "        shape,\n",
    "    )\n",
    "    rand_pool += np.repeat(np.array([x]), pool_factor * batch_size, 0)\n",
    "    rand_pool = rand_pool.astype(ART_NUMPY_DTYPE)\n",
    "    if hasattr(classifier, \"clip_values\") and classifier.clip_values is not None:\n",
    "        np.clip(rand_pool, classifier.clip_values[0], classifier.clip_values[1], out=rand_pool)\n",
    "\n",
    "    # Change norm since q = p / (p-1)\n",
    "    if norm == 1:\n",
    "        norm = np.inf\n",
    "    elif norm == np.inf:\n",
    "        norm = 1\n",
    "    elif norm != 2:  # pragma: no cover\n",
    "        raise ValueError(f\"Norm {norm} not supported\")\n",
    "\n",
    "    # Compute gradients for all samples in rand_pool\n",
    "    for i in range(batch_size):\n",
    "        rand_pool_batch = rand_pool[i * pool_factor : (i + 1) * pool_factor]\n",
    "\n",
    "        # Compute gradients\n",
    "        grad_pred_class = classifier.class_gradient(rand_pool_batch, label=pred_class)\n",
    "\n",
    "        if np.isnan(grad_pred_class).any() :  # pragma: no cover\n",
    "            raise Exception(\"The classifier results NaN gradients.\")\n",
    "\n",
    "        grad = grad_pred_class\n",
    "        grad = np.reshape(grad, (pool_factor, -1))\n",
    "        grad = np.linalg.norm(grad, ord=norm, axis=1)\n",
    "        rand_pool_grad_set.extend(grad)\n",
    "\n",
    "    rand_pool_grads = np.array(rand_pool_grad_set)\n",
    "\n",
    "    # Loop over the batches\n",
    "    for _ in range(nb_batches):\n",
    "        # Random selection of gradients\n",
    "        grad_norm = rand_pool_grads[np.random.choice(pool_factor * batch_size, batch_size)]\n",
    "        grad_norm = np.max(grad_norm)\n",
    "        grad_norm_set.append(grad_norm)\n",
    "\n",
    "    # Maximum likelihood estimation for max gradient norms\n",
    "    [_, loc, _] = weibull_min.fit(-np.array(grad_norm_set), c_init, optimizer=scipy_optimizer)\n",
    "\n",
    "    # Compute function value\n",
    "    values = classifier.predict(np.array([x]))\n",
    "#     value = values[:, pred_class] - prob_constant\n",
    "    value = values[:, pred_class] * np.log(1+values[:, pred_class])\n",
    "\n",
    "    # Compute scores\n",
    "#     score = np.min([-value[0] / loc, radius])\n",
    "    score = -value[0] / loc\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816d152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
