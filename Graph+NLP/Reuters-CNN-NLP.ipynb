{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffaea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd98a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "#                                                          num_words=None,\n",
    "#                                                          skip_top=0,\n",
    "#                                                          maxlen=None,\n",
    "#                                                          test_split=0.2,\n",
    "#                                                          seed=113,\n",
    "#                                                          start_char=1,\n",
    "#                                                          oov_char=2,\n",
    "#                                                          index_from=3)\n",
    "\n",
    "(X_train_seq, Y_train), (X_test_seq, Y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b190619",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = -1\n",
    "\n",
    "for seq in X_train_seq:\n",
    "    max_index = max(seq)\n",
    "    if max_index > vocabulary_size:\n",
    "        vocabulary_size = max_index\n",
    "\n",
    "for seq in X_test_seq:\n",
    "    max_index = max(seq)\n",
    "    if max_index > vocabulary_size:\n",
    "        vocabulary_size = max_index\n",
    "\n",
    "vocabulary_size += 1\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train_seq, maxlen=100)\n",
    "X_test = sequence.pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b885b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,) (8982, 46) (2246,) (2246, 46)\n",
      "(87,) (145,)\n",
      "(8982, 100) (2246, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_seq), np.shape(Y_train), np.shape(X_test_seq), np.shape(Y_test))\n",
    "print(np.shape(X_train_seq[0]), np.shape(X_test_seq[0]))\n",
    "print(np.shape(X_train), np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1841c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96d03e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 300)          9294600   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 100, 128)          115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 50, 64)            24640     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25, 1024)          66560     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25, 1024)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46)                1177646   \n",
      "=================================================================\n",
      "Total params: 10,678,774\n",
      "Trainable params: 10,678,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "71/71 [==============================] - 2s 15ms/step - loss: 2.1528 - accuracy: 0.3996\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 1.6095 - accuracy: 0.5582\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 1.3220 - accuracy: 0.6408\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 1.0781 - accuracy: 0.7035\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.8584 - accuracy: 0.7637\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.6503 - accuracy: 0.8162\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8909\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.3207 - accuracy: 0.9142\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2825 - accuracy: 0.9236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f97f59d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=300, input_dim=vocabulary_size, input_length=100))\n",
    "\n",
    "# model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ebec63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1593668907880783, 0.9582498073577881]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30cf269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 4ms/step - loss: 2.1951 - accuracy: 0.6336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1950700283050537, 0.6335707902908325]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae521e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
