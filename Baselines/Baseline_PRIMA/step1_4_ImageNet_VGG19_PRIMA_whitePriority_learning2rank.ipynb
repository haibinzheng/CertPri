{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b61167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as BE\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from progressbar import ProgressBar\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import sys\n",
    "import scipy.io\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "\n",
    "import xgboost\n",
    "from sklearn import model_selection\n",
    "\n",
    "# from tensorflow.keras import backend as BE\n",
    "# from Integrated_Gradients_algorithm import *\n",
    "# from GradVisualizer import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess=tf.compat.v1.Session(config=config) \n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5a05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../datasets/ImageNetVal/'\n",
    "file_name = getfile_name(DATA_PATH)\n",
    "file_name = np.sort(file_name)\n",
    "\n",
    "f = open(\"/public/liujiawei/huawei/ZHB/ADF-master/datasets/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt\",encoding = \"utf-8\")\n",
    "val_ground_truth = f.read()\n",
    "val_ground_truth = val_ground_truth.split('\\n')\n",
    "for i in range(len(val_ground_truth)-1):\n",
    "    val_ground_truth[i] = int(val_ground_truth[i])\n",
    "    \n",
    "vgg19_json = json.load(open('/public/liujiawei/.keras/models/imagenet_class_index.json','r',encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a62ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n04263257\n",
      "soup bowl\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "synsets = scipy.io.loadmat(os.path.join('/public/liujiawei/huawei/ZHB/ADF-master/datasets', \n",
    "                                        'ILSVRC2012_devkit_t12', 'data', 'meta.mat'))['synsets']\n",
    "\n",
    "ILSVRC2012_ID = [s[0][0][0][0] for s in synsets]\n",
    "\n",
    "index1 = 821\n",
    "WNID = [s[0][1][0] for s in synsets]\n",
    "print(WNID[index1])\n",
    "\n",
    "words = [s[0][2][0] for s in synsets]\n",
    "print(words[index1])\n",
    "\n",
    "num_train_images = [s[0][7][0][0] for s in synsets]\n",
    "print(num_train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f419fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预设的参数\n",
    "feature_PRIMA_data = np.load('./featureExtraction/ImageNet_10000samplesBlackFeature.npy', \n",
    "                        allow_pickle=True)\n",
    "total_sample_num = 3000  # 待测的总样本数\n",
    "img_size = (224,224)\n",
    "feature_PRIMA_model = np.load('./featureExtraction/ImageNet_'+str(total_sample_num)+'samplesWhiteFeature.npy', \n",
    "                        allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f267d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "X_xgboost = np.zeros((total_sample_num, (7+10+7+10)))\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(0,total_sample_num)):\n",
    "    X_xgboost[i, 0] = feature_PRIMA_data.item()['euler'][i]\n",
    "    X_xgboost[i, 1] = feature_PRIMA_data.item()['mahat'][i]\n",
    "    X_xgboost[i, 2] = feature_PRIMA_data.item()['qube'][i]\n",
    "    X_xgboost[i, 3] = feature_PRIMA_data.item()['cos'][i][0]\n",
    "    X_xgboost[i, 4] = feature_PRIMA_data.item()['difference'][i]\n",
    "    X_xgboost[i, 5] = feature_PRIMA_data.item()['wnum'][i]\n",
    "    X_xgboost[i, 6] = feature_PRIMA_data.item()['num_mc'][i]\n",
    "    X_xgboost[i, 7:17] = feature_PRIMA_data.item()['fenbu'][i]\n",
    "    \n",
    "    X_xgboost[i, 17] = feature_PRIMA_model.item()['euler'][i]\n",
    "    X_xgboost[i, 18] = feature_PRIMA_model.item()['mahat'][i]\n",
    "    X_xgboost[i, 19] = feature_PRIMA_model.item()['qube'][i]\n",
    "    X_xgboost[i, 20] = feature_PRIMA_model.item()['cos'][i]\n",
    "    X_xgboost[i, 21] = feature_PRIMA_model.item()['difference'][i]\n",
    "    X_xgboost[i, 22] = feature_PRIMA_model.item()['wnum'][i]\n",
    "    X_xgboost[i, 23] = feature_PRIMA_model.item()['num_mc'][i]\n",
    "    X_xgboost[i, 24:34] = feature_PRIMA_model.item()['fenbu'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5fda22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# 用于XGBoost训练的样本的真实标签，即是否为误分类\n",
    "Y_xgboost = []\n",
    "top_set = 1 # 预测的前n个类中包含真实标签则表示预测正确\n",
    "predicted_confidence = feature_PRIMA_model.item()['predicted_confidence']\n",
    "ground_truth_label = feature_PRIMA_model.item()['ground_truth_label']\n",
    "pbar = ProgressBar()\n",
    "for i in pbar(range(0, total_sample_num)):\n",
    "    if top_set is not None:\n",
    "        if not get_acc(predict_label=decode_predictions(predicted_confidence[i], top=top_set), \n",
    "                           ground_truth=ground_truth_label[i]):\n",
    "            Y_xgboost.append(1)\n",
    "        else:\n",
    "            Y_xgboost.append(0)\n",
    "            \n",
    "Y_xgboost = np.array(Y_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cf557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=10, n_jobs=80,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=10, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_xgboost = 2000  # 用于训练的样本数\n",
    "bottom_train_xgboost = range(total_sample_num-train_num_xgboost, total_sample_num)  # 后bottom_train_num_xgboost个作为训练的样本\n",
    "xg_reg = xgboost.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(X_xgboost[bottom_train_xgboost], Y_xgboost[bottom_train_xgboost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f50864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 90% |################################################################        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APFD:  0.7273917378917378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAUC:  0.8810808944142278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 预测xgboost的测试集部分\n",
    "top_test_xgboost = range(0, 1000)  # 前top_test_num_xgboost个作为测试的样本\n",
    "\n",
    "y_pred_xgbooxt = xg_reg.predict(X_xgboost[top_test_xgboost])\n",
    "indexs = np.argsort(y_pred_xgbooxt)\n",
    "indexs = indexs[::-1]\n",
    "APFD,_,wrong_index = get_APFD(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label)[top_test_xgboost],\n",
    "                              predicted_confidence=np.array(predicted_confidence[top_test_xgboost]), \n",
    "                              top_set=top_set, decode_predictions=decode_predictions)\n",
    "print(\"APFD: \", APFD)\n",
    "RAUC,_,_ = get_RAUC(Gini_indexs=indexs, ground_truth_label=np.array(ground_truth_label)[top_test_xgboost], \n",
    "                predicted_confidence=np.array(predicted_confidence[top_test_xgboost]), \n",
    "                    top_set=top_set, decode_predictions=decode_predictions)\n",
    "print(\"RAUC: \", RAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697aa037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
