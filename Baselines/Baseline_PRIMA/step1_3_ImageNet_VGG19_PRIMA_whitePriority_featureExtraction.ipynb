{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b61167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as BE\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from progressbar import ProgressBar\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import sys\n",
    "import scipy.io\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "from keras.models import clone_model\n",
    "\n",
    "# from tensorflow.keras import backend as BE\n",
    "# from Integrated_Gradients_algorithm import *\n",
    "# from GradVisualizer import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess=tf.compat.v1.Session(config=config) \n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5a05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../datasets/ImageNetVal/'\n",
    "file_name = getfile_name(DATA_PATH)\n",
    "file_name = np.sort(file_name)\n",
    "\n",
    "f = open(\"/public/liujiawei/huawei/ZHB/ADF-master/datasets/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt\",encoding = \"utf-8\")\n",
    "val_ground_truth = f.read()\n",
    "val_ground_truth = val_ground_truth.split('\\n')\n",
    "for i in range(len(val_ground_truth)-1):\n",
    "    val_ground_truth[i] = int(val_ground_truth[i])\n",
    "\n",
    "vgg19_json = json.load(open('/public/liujiawei/.keras/models/imagenet_class_index.json','r',encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6056c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a62ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n04263257\n",
      "soup bowl\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "synsets = scipy.io.loadmat(os.path.join('/public/liujiawei/huawei/ZHB/ADF-master/datasets', \n",
    "                                        'ILSVRC2012_devkit_t12', 'data', 'meta.mat'))['synsets']\n",
    "\n",
    "ILSVRC2012_ID = [s[0][0][0][0] for s in synsets]\n",
    "\n",
    "index1 = 821\n",
    "WNID = [s[0][1][0] for s in synsets]\n",
    "print(WNID[index1])\n",
    "\n",
    "words = [s[0][2][0] for s in synsets]\n",
    "print(words[index1])\n",
    "\n",
    "num_train_images = [s[0][7][0][0] for s in synsets]\n",
    "print(num_train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258f8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340779b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预设的参数\n",
    "total_sample_num = 3000  # 待测的总样本数\n",
    "model_mutant_num = 10 # 单个模型得到的变异体数量，PRIMA中设置变异模型为100个\n",
    "weight_mutant_rate = 0.1  # 模型中的权重修改比例，，PRIMA中设置为10%\n",
    "img_size = (224,224)\n",
    "layer_pos = 24  # 修改的层的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62673669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7d801f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd788358bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "id_ = []\n",
    "euler_ = []\n",
    "mahat_ = []\n",
    "qube_ = []\n",
    "cos_ = []\n",
    "difference_ = []\n",
    "wrong_class_num_ = []\n",
    "max_class_num_ = []\n",
    "cos_dis_ = []\n",
    "\n",
    "predicted_confidence = []\n",
    "ground_truth_label = []\n",
    "\n",
    "# 获取模型某一层的激活输出\n",
    "layer_name = 'fc1'\n",
    "hidden_layer_Model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)\n",
    "\n",
    "# 搭建部分的模型\n",
    "Input_hidden = Input( shape=( np.shape(base_model.get_layer(layer_name).output[0]) ) ) \n",
    "partial_model_Model = Input_hidden\n",
    "layer_pos = getLayerIndexByName(base_model, layer_name)\n",
    "for layer in base_model.layers[layer_pos+1:] :\n",
    "    partial_model_Model = layer(partial_model_Model)\n",
    "partial_model_Model = Model(inputs=Input_hidden, outputs=partial_model_Model)\n",
    "\n",
    "for i in pbar(range(0, total_sample_num)):\n",
    "    img_path = DATA_PATH + file_name[i]\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    x_tmp = image.img_to_array(img)\n",
    "    x_tmp = np.expand_dims(x_tmp, axis=0)\n",
    "    x_tmp = preprocess_input(x_tmp)\n",
    "    pre_tmp = base_model.predict(np.reshape(x_tmp, [-1,img_size[0],img_size[1],3]))\n",
    "\n",
    "    a = pre_tmp  #ori_prob[i] # 样本的预测置信度\n",
    "    max_value = np.max(a)  # 预测置信度的最大概率值\n",
    "    max_value_pos = np.argmax(a)   # 样本的预测标签\n",
    "#     perturbated_prediction   # 样本扰动后的预测置信度\n",
    "    # 对于待测样本的变异扰动样本的特征提取\n",
    "    euler = 0\n",
    "    mahat = 0\n",
    "    qube = 0\n",
    "    cos = 0\n",
    "    difference = 0\n",
    "    different_class = []\n",
    "    cos_list = []\n",
    "    \n",
    "    # 进行模型的变异操作\n",
    "    perturbated_prediction = []\n",
    "    for ii in range(0, int(model_mutant_num/4)): # 有四种模型变异操作\n",
    "        conf_NAI = NeuActInverse_confidence(x_tmp, hidden_layer_Model, \n",
    "                                            partial_model_Model, weight_mutant_rate)  # 神经元激活翻转\n",
    "        conf_NEB = NeuEffBlock_confidence(x_tmp, hidden_layer_Model, \n",
    "                                          partial_model_Model, weight_mutant_rate)  # 神经元激活置零\n",
    "        conf_GF = GaussFuzz_confidence(x_tmp, base_model, 0, 0.1, layer_name)  # 神经元激活添加高斯噪声\n",
    "        conf_WS = WeightShuffl_confidence(x_tmp, base_model, layer_name, weight_mutant_rate)  # 部分权重值打乱\n",
    "        perturbated_prediction.append(conf_NAI)\n",
    "        perturbated_prediction.append(conf_NEB)\n",
    "        perturbated_prediction.append(conf_GF)\n",
    "        perturbated_prediction.append(conf_WS)\n",
    "    perturbated_prediction = np.squeeze(np.array(perturbated_prediction), axis=1)\n",
    "    \n",
    "    for pp in perturbated_prediction:  # 取每一种变异扰动样本的置信度值\n",
    "        pro = pp\n",
    "        opro = a\n",
    "        # if np.argmax(ii) != result[i]:\n",
    "        difference += abs(max_value - pp[max_value_pos])\n",
    "        euler += np.linalg.norm(pro - opro)\n",
    "        mahat += np.linalg.norm(pro - opro, ord=1)\n",
    "        qube += np.linalg.norm(pro - opro, ord=np.inf)\n",
    "        co = (1 - (np.dot(pro, opro.T) / (np.linalg.norm(pro) * (np.linalg.norm(opro)))))\n",
    "        if co < 0:\n",
    "            co = 0\n",
    "        elif co > 1:\n",
    "            co = 1\n",
    "        cos += co\n",
    "        cos_list.append(co)\n",
    "        if np.argmax(pp) != max_value_pos:\n",
    "            different_class.append(np.argmax(pp))\n",
    "    cos_dis = cos_distribution(cos_list)\n",
    "    dic = {}\n",
    "    for key in different_class:\n",
    "        dic[key] = dic.get(key, 0) + 1\n",
    "    wrong_class_num = len(dic)\n",
    "    if len(dic)>0:\n",
    "        max_class_num = max(dic.values())\n",
    "    else :\n",
    "        max_class_num = 0\n",
    "\n",
    "    id_.append(i)\n",
    "    euler_.append(euler)\n",
    "    mahat_.append(mahat)\n",
    "    qube_.append(qube)\n",
    "    cos_.append(cos)\n",
    "    difference_.append(difference)\n",
    "    wrong_class_num_.append(wrong_class_num)\n",
    "    max_class_num_.append(max_class_num)\n",
    "    cos_dis_.append(cos_dis)\n",
    "    predicted_confidence.append(pre_tmp)\n",
    "    ground_truth_label.append(WNID[val_ground_truth[i]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c66160",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = np.array(id_)\n",
    "euler_ = np.array(euler_)\n",
    "mahat_ = np.array(mahat_)\n",
    "qube_ = np.array(qube_)\n",
    "cos_ = np.array(cos_)\n",
    "difference_ = np.array(difference_)\n",
    "wrong_class_num_ = np.array(wrong_class_num_)\n",
    "max_class_num_ = np.array(max_class_num_)\n",
    "cos_dis_ = np.array(cos_dis_)\n",
    "predicted_confidence = np.array(predicted_confidence)\n",
    "\n",
    "np.save('./featureExtraction/ImageNet_'+str(total_sample_num)+'samplesWhiteFeature.npy',{\n",
    "    'id': id_,\n",
    "    'euler': euler_,\n",
    "    'mahat': mahat_,\n",
    "    'qube': qube_,\n",
    "    'cos': cos_,\n",
    "    'difference': difference_,\n",
    "    'wnum': wrong_class_num_,\n",
    "    'num_mc': max_class_num_,\n",
    "    'fenbu': cos_dis_,\n",
    "    'predicted_confidence': predicted_confidence,\n",
    "    'ground_truth_label': ground_truth_label,\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095390e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
