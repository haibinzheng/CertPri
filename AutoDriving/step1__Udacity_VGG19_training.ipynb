{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc76159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from GradPri_utils.utils import *\n",
    "\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from progressbar import ProgressBar\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1cba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/public/liujiawei/ZHB/GradPri/UdacityData'\n",
    "\n",
    "X_train = np.load(os.path.join(DATA_PATH, 'train_X.npy'))\n",
    "Y_train = np.load(os.path.join(DATA_PATH, 'train_Y.npy'))\n",
    "X_test = np.load(os.path.join(DATA_PATH, 'test_X.npy'))\n",
    "Y_test = np.load(os.path.join(DATA_PATH, 'test_Y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fdbf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (33808, 128, 128, 3)\n",
      "33808 train samples\n",
      "5279 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# X_train /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9b639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Lambda(augment_2d,\n",
    "#                  input_shape=x_train.shape[1:],\n",
    "#                  arguments={'rotation': 8.0, 'horizontal_flip': True}))\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), padding='same', name = 'block1_conv1', input_shape=input_shape))\n",
    "model.add(BatchNormalization(name = 'block1_bn1'))\n",
    "model.add(Activation('relu', name = 'block1_act1'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', name = 'block1_conv2'))\n",
    "model.add(BatchNormalization(name = 'block1_bn2'))\n",
    "model.add(Activation('relu', name = 'block1_act2'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool'))\n",
    "model.add(Dropout(0.25, name='block1_drop'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3, 3), padding='same', name = 'block2_conv1'))\n",
    "model.add(BatchNormalization(name = 'block2_bn1'))\n",
    "model.add(Activation('relu', name = 'block2_act1'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', name = 'block2_conv2'))\n",
    "model.add(BatchNormalization(name = 'block2_bn2'))\n",
    "model.add(Activation('relu', name = 'block2_act2'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block2_pool'))\n",
    "model.add(Dropout(0.25, name='block2_drop'))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name = 'block3_conv1'))\n",
    "model.add(BatchNormalization(name = 'block3_bn1'))\n",
    "model.add(Activation('relu', name = 'block3_act1'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name = 'block3_conv2'))\n",
    "model.add(BatchNormalization(name = 'block3_bn2'))\n",
    "model.add(Activation('relu', name = 'block3_act2'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name = 'block3_conv3'))\n",
    "model.add(BatchNormalization(name = 'block3_bn3'))\n",
    "model.add(Activation('relu', name = 'block3_act3'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name = 'block3_conv4'))\n",
    "model.add(BatchNormalization(name = 'block3_bn4'))\n",
    "model.add(Activation('relu', name = 'block3_act4'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block3_pool'))\n",
    "model.add(Dropout(0.25, name='block3_drop'))\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block4_conv1'))\n",
    "model.add(BatchNormalization(name = 'block4_bn1'))\n",
    "model.add(Activation('relu', name = 'block4_act1'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block4_conv2'))\n",
    "model.add(BatchNormalization(name = 'block4_bn2'))\n",
    "model.add(Activation('relu', name = 'block4_act2'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block4_conv3'))\n",
    "model.add(BatchNormalization(name = 'block4_bn3'))\n",
    "model.add(Activation('relu', name = 'block4_act3'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block4_conv4'))\n",
    "model.add(BatchNormalization(name = 'block4_bn4'))\n",
    "model.add(Activation('relu', name = 'block4_act4'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block4_pool'))\n",
    "model.add(Dropout(0.25, name='block4_drop'))\n",
    "\n",
    "# Block 5\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block5_conv1'))\n",
    "model.add(BatchNormalization(name = 'block5_bn1'))\n",
    "model.add(Activation('relu', name = 'block5_act1'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block5_conv2'))\n",
    "model.add(BatchNormalization(name = 'block5_bn2'))\n",
    "model.add(Activation('relu', name = 'block5_act2'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block5_conv3'))\n",
    "model.add(BatchNormalization(name = 'block5_bn3'))\n",
    "model.add(Activation('relu', name = 'block5_act3'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name = 'block5_conv4'))\n",
    "model.add(BatchNormalization(name = 'block5_bn4'))\n",
    "model.add(Activation('relu', name = 'block5_act4'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block5_pool'))\n",
    "model.add(Dropout(0.25, name='block5_drop'))\n",
    "\n",
    "# include_top\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5, name='drop1'))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dropout(0.5, name='drop2'))\n",
    "model.add(Dense(1, activation='tanh', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e330a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_bn1 (BatchNormalizati (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "block1_act1 (Activation)     (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_bn2 (BatchNormalizati (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "block1_act2 (Activation)     (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_drop (Dropout)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_bn1 (BatchNormalizati (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "block2_act1 (Activation)     (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_bn2 (BatchNormalizati (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "block2_act2 (Activation)     (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_drop (Dropout)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_bn1 (BatchNormalizati (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block3_act1 (Activation)     (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_bn2 (BatchNormalizati (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block3_act2 (Activation)     (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_bn3 (BatchNormalizati (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block3_act3 (Activation)     (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_bn4 (BatchNormalizati (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block3_act4 (Activation)     (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_drop (Dropout)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_bn1 (BatchNormalizati (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "block4_act1 (Activation)     (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_bn2 (BatchNormalizati (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "block4_act2 (Activation)     (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_bn3 (BatchNormalizati (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "block4_act3 (Activation)     (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_bn4 (BatchNormalizati (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "block4_act4 (Activation)     (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_drop (Dropout)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_bn1 (BatchNormalizati (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_act1 (Activation)     (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_bn2 (BatchNormalizati (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_act2 (Activation)     (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_bn3 (BatchNormalizati (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_act3 (Activation)     (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_bn4 (BatchNormalizati (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_act4 (Activation)     (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_drop (Dropout)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "drop2 (Dropout)              (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 70,390,337\n",
      "Trainable params: 70,379,329\n",
      "Non-trainable params: 11,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6acbd875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "265/265 [==============================] - 61s 224ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "\n",
      "Epoch 00001: val_mse improved from inf to 0.03974, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 2/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00002: val_mse improved from 0.03974 to 0.01712, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 3/50\n",
      "265/265 [==============================] - 58s 220ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00003: val_mse did not improve from 0.01712\n",
      "Epoch 4/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00004: val_mse did not improve from 0.01712\n",
      "Epoch 5/50\n",
      "265/265 [==============================] - 55s 208ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "\n",
      "Epoch 00005: val_mse did not improve from 0.01712\n",
      "Epoch 6/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "\n",
      "Epoch 00006: val_mse did not improve from 0.01712\n",
      "Epoch 7/50\n",
      "265/265 [==============================] - 58s 220ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "\n",
      "Epoch 00007: val_mse improved from 0.01712 to 0.01689, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 8/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "\n",
      "Epoch 00008: val_mse did not improve from 0.01689\n",
      "Epoch 9/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "\n",
      "Epoch 00009: val_mse improved from 0.01689 to 0.01684, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 10/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "\n",
      "Epoch 00010: val_mse improved from 0.01684 to 0.01343, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 11/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "\n",
      "Epoch 00011: val_mse did not improve from 0.01343\n",
      "Epoch 12/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "\n",
      "Epoch 00012: val_mse did not improve from 0.01343\n",
      "Epoch 13/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "\n",
      "Epoch 00013: val_mse did not improve from 0.01343\n",
      "Epoch 14/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "\n",
      "Epoch 00014: val_mse did not improve from 0.01343\n",
      "Epoch 15/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "\n",
      "Epoch 00015: val_mse did not improve from 0.01343\n",
      "Epoch 16/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "\n",
      "Epoch 00016: val_mse improved from 0.01343 to 0.01342, saving model to ./model/Udacity_VGG19.h5\n",
      "Epoch 17/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "\n",
      "Epoch 00017: val_mse did not improve from 0.01342\n",
      "Epoch 18/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "\n",
      "Epoch 00018: val_mse did not improve from 0.01342\n",
      "Epoch 19/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "\n",
      "Epoch 00019: val_mse did not improve from 0.01342\n",
      "Epoch 20/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "\n",
      "Epoch 00020: val_mse did not improve from 0.01342\n",
      "Epoch 21/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00021: val_mse did not improve from 0.01342\n",
      "Epoch 22/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "\n",
      "Epoch 00022: val_mse did not improve from 0.01342\n",
      "Epoch 23/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "\n",
      "Epoch 00023: val_mse did not improve from 0.01342\n",
      "Epoch 24/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "\n",
      "Epoch 00024: val_mse did not improve from 0.01342\n",
      "Epoch 25/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "\n",
      "Epoch 00025: val_mse did not improve from 0.01342\n",
      "Epoch 26/50\n",
      "265/265 [==============================] - 58s 220ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "\n",
      "Epoch 00026: val_mse did not improve from 0.01342\n",
      "Epoch 27/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "\n",
      "Epoch 00027: val_mse did not improve from 0.01342\n",
      "Epoch 28/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00028: val_mse did not improve from 0.01342\n",
      "Epoch 29/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00029: val_mse did not improve from 0.01342\n",
      "Epoch 30/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00030: val_mse did not improve from 0.01342\n",
      "Epoch 31/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "\n",
      "Epoch 00031: val_mse did not improve from 0.01342\n",
      "Epoch 32/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "\n",
      "Epoch 00032: val_mse did not improve from 0.01342\n",
      "Epoch 33/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "\n",
      "Epoch 00033: val_mse did not improve from 0.01342\n",
      "Epoch 34/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00034: val_mse did not improve from 0.01342\n",
      "Epoch 35/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00035: val_mse did not improve from 0.01342\n",
      "Epoch 36/50\n",
      "265/265 [==============================] - 55s 206ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "\n",
      "Epoch 00036: val_mse did not improve from 0.01342\n",
      "Epoch 37/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "\n",
      "Epoch 00037: val_mse did not improve from 0.01342\n",
      "Epoch 38/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "\n",
      "Epoch 00038: val_mse did not improve from 0.01342\n",
      "Epoch 39/50\n",
      "265/265 [==============================] - 57s 217ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "\n",
      "Epoch 00039: val_mse did not improve from 0.01342\n",
      "Epoch 40/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "\n",
      "Epoch 00040: val_mse did not improve from 0.01342\n",
      "Epoch 41/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00041: val_mse did not improve from 0.01342\n",
      "Epoch 42/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "\n",
      "Epoch 00042: val_mse did not improve from 0.01342\n",
      "Epoch 43/50\n",
      "265/265 [==============================] - 57s 216ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "\n",
      "Epoch 00043: val_mse did not improve from 0.01342\n",
      "Epoch 44/50\n",
      "265/265 [==============================] - 58s 219ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "\n",
      "Epoch 00044: val_mse did not improve from 0.01342\n",
      "Epoch 45/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "\n",
      "Epoch 00045: val_mse did not improve from 0.01342\n",
      "Epoch 46/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "\n",
      "Epoch 00046: val_mse did not improve from 0.01342\n",
      "Epoch 47/50\n",
      "265/265 [==============================] - 58s 221ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "\n",
      "Epoch 00047: val_mse did not improve from 0.01342\n",
      "Epoch 48/50\n",
      "265/265 [==============================] - 58s 217ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "\n",
      "Epoch 00048: val_mse did not improve from 0.01342\n",
      "Epoch 49/50\n",
      "265/265 [==============================] - 58s 218ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "\n",
      "Epoch 00049: val_mse did not improve from 0.01342\n",
      "Epoch 50/50\n",
      "265/265 [==============================] - 58s 221ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "\n",
      "Epoch 00050: val_mse did not improve from 0.01342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf181fada0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(\"./model/Udacity_VGG19.h5\")\n",
    "# # initiate RMSprop optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00004) # 0.00005\n",
    "\n",
    "# # Let's train the model using RMSprop\n",
    "model.compile(loss='mse',\n",
    "              optimizer=opt,\n",
    "              metrics=['mse'])\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"./model/Udacity_VGG19.h5\", \n",
    "                                                monitor='val_mse', \n",
    "                                                verbose=1, save_best_only=True, mode = 'min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=50, shuffle=True,\n",
    "          validation_data=(X_test[0:2000], Y_test[0:2000]), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be36a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3044412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"./model/Udacity_VGG19.h5\")\n",
    "pred_tmp = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d0b9221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12586020573124734\n"
     ]
    }
   ],
   "source": [
    "rmse = 0\n",
    "for i in range(len(pred_tmp)):\n",
    "    rmse = rmse + pow(pred_tmp[i][0] - Y_test[i], 2)\n",
    "rmse = rmse/len(pred_tmp)\n",
    "rmse = np.sqrt(rmse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5f41af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4187 0.015840791386711836\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "for i in range(len(pred_tmp)):\n",
    "    rmse.append( np.sum(pow( pred_tmp[i][0] - Y_test[i], 2)))\n",
    "rmse1 = np.mean(rmse)\n",
    "# rmse1 = np.sqrt(rmse1)\n",
    "ss = 0\n",
    "for i in rmse:\n",
    "    if i<rmse1:\n",
    "        ss += 1\n",
    "print(ss, rmse1)\n",
    "# print(rmse1, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc7517a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 3s 20ms/step - loss: 0.0158 - mse: 0.0158\n",
      "[0.015840787440538406, 0.015840787440538406]\n"
     ]
    }
   ],
   "source": [
    "metric_tmp = model.evaluate(X_test, Y_test)\n",
    "print(metric_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edf91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27235d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2131508352233873\n"
     ]
    }
   ],
   "source": [
    "rmse = 0\n",
    "for i in range(len(pred_tmp)):\n",
    "    rmse = rmse + pow(0 - Y_test[i], 2)\n",
    "rmse = rmse/len(pred_tmp)\n",
    "rmse = np.sqrt(rmse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee88d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
